{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">üïµüèª EDA on Vehicle Sales Data üèéÔ∏è</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº ***Introduction***\n",
    "\n",
    "<p style=\"text-align: justify;\">My client company is JJ motors.\n",
    "They are one of the leading car resellers in US.They have provided me a dataset of vehicle sales data. They want to find some business insigts from this dataset so that they can improve they sales in the market.\n",
    "\n",
    "\n",
    "## üßø ***Objective***\n",
    " I will be conducting  Exploratory Data Analysis (EDA) on Vehicle Sales Data dataset and try to get an insights of the dataset. I have some business questions in mind which will help the company in improving their sales. Let's see how we can find the answers to these questions. .I will be loading the dataset and then try to find and any relationships, treands and patterns between among the various features of the dataset. Also, I will be trying to find answers to the below set of questions.</p>\n",
    "\n",
    "Questions\n",
    "1. What is the trend in vehicle sales over the years based on the \"year\" column?\n",
    "2. Which vehicle make dominates the sales in the dataset?\n",
    "3. Are there any particular models that consistently perform better in terms of sales?\n",
    "4. How does the distribution of vehicle trims affect their selling prices?\n",
    "5. What body type is most commonly sold in the dataset?\n",
    "6. Is there any correlation between transmission type and selling price?\n",
    "7. Does the VIN (Vehicle Identification Number) have any influence on sales performance?\n",
    "8. Which states contribute the most to overall vehicle sales?\n",
    "9. How does the condition of the vehicle impact its selling price?\n",
    "10. Is there a relationship between odometer reading and selling price?\n",
    "11. Are certain colors more popular among buyers, and do they affect selling prices?\n",
    "12. Does the interior type influence the selling price of a vehicle?\n",
    "13. What type of sellers (e.g., dealerships, private sellers) are more successful in selling vehicles?\n",
    "14. Is there a correlation between the Manheim Market Report (MMR) value and the actual selling price of vehicles?\n",
    "15. How does the sale date (month, day of the week) affect the selling price and volume of vehicle sales?\n",
    "\n",
    "**About the data**  \n",
    "This [**dataset**](https://www.kaggle.com/datasets/syedanwarafridi/vehicle-sales-data/code) contains 16 columns of sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üç¥***Table of Content***\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üí≠ **My taughts on the dataset**\n",
    "##### üßπ **Data Cleaning**\n",
    "##### ‚ùì **Business Questions**\n",
    "##### üí° **Conclusion**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚¨á **Importing Libraries**\n",
    "<a id='library'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from dateutil import parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä **Importing Dataset**\n",
    "<a id='dataset'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/009. eda_on_ecommerce_dataset/dataset/car_prices.csv')\n",
    "\n",
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"Number of columns.   :\", df.shape[1])\n",
    "print(\"=\"*130)\n",
    "\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data Dimensions\n",
    "\n",
    "After loading the dataset into the DataFrame `df`, I'm interested in knowing its dimensions of the datafame.\n",
    "By Using the `.shape` attribute , I will retrieve the number of rows and columns in the form of a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above there are 5558837 rows and 16 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a short summary of the dataframe\n",
    "\n",
    "- Here we use`info()` method to get a shortsummary of the DataFrame. It will include the number of non-null values, Data Types, and Memory Usage etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the above response the count in the **Non-Null** column is less than the total columns i.e. 558837, that means that there are many NULL values in the dataset. Which we will take care in the data cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us check datatypes of the columns\n",
    "- I will be using `dtypes` attribute to get the datatypes of the columns.\n",
    "- If you have notices we also got the same details in `.info()` attribute above. But I like to view it seperately we get a getter understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a Descriptive Statistics\n",
    "\n",
    "- `df.describe()`will help us generate a descriptive statistics of numerical columns of the DataFrame. It will provide us various functions such as mean, count, Standard Deviation, Min, Max and percentiles.\n",
    "- Let's check and try to study our dataset.\n",
    "- I have used Transpose here as I want the columns of my DataFrame as the index. This especially helps when I have many numrical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HAS TO BE RE-WRITTEN**\n",
    "1. **Year**:\n",
    "   - The dataset spans from the year 1982 to 2015, with the majority of vehicles being sold between 2007 and 2013.\n",
    "   - The average year of sale is approximately 2010, indicating that the dataset predominantly consists of relatively recent vehicle sales.\n",
    "\n",
    "2. **Condition**:\n",
    "   - The condition values range from 1 to 49, with higher values representing better conditions.\n",
    "   - The average condition value is around 30, suggesting that the vehicles in the dataset generally have moderate to good conditions.\n",
    "\n",
    "3. **Odometer**:\n",
    "   - Odometer readings range from 1 to 999,999 miles.\n",
    "   - The average odometer reading is approximately 68,320 miles, indicating that the vehicles vary widely in terms of mileage.\n",
    "   - The median (50th percentile) odometer reading is 52,254 miles, suggesting that half of the vehicles have odometer readings below this value.\n",
    "\n",
    "4. **MMR (Market Median Retail)**:\n",
    "   - MMR values represent the median retail price of vehicles in the market.\n",
    "   - The MMR values range from 25 to 182,000, with an average MMR of approximately 13,769.\n",
    "   - The median MMR is 12,250, indicating that half of the vehicles in the dataset have market median retail prices below this value.\n",
    "\n",
    "5. **Selling Price**:\n",
    "   - Selling prices of vehicles in the dataset range from 1 to 230,000.\n",
    "   - The average selling price is approximately 13,611, suggesting that the dataset contains a mix of vehicles across different price ranges.\n",
    "   - The median selling price is 12,100, indicating that half of the vehicles were sold at prices below this value.\n",
    "\n",
    "Overall, this summary provides valuable insights into the distribution and characteristics of the vehicle sales dataset, including information about the years of sale, vehicle conditions, mileage, market median retail prices, and selling prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check how much percentage of the columns are null. If they are negligible percentage then we can just drop the columns. Otherwise I will fill the na values with the meaninfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in df:\n",
    "    null_percentage[column] = round(( ( df[column].isnull().sum() ) / len(df)) * 100,2)\n",
    "np_df = pd.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transmission\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the null_percentage for each column is negligible. The max is for Transmission is 11.69%, which is negligible when we consider the datasize, i.e. 558837 of data. Hence I will be droping the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIN number is not usefull for my analysis, hence I will be droping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"vin\",axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can also see that sale date is different format. So I am going to use `dateutil.parser` module to clean it and convert it to datetime format. This module will automatically detect varies formats and convert it for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saledatetime']  =    pd.to_datetime(df['saledate' ].apply( parser.parse),utc=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can \n",
    "1. drop the older  `saledate` column, \n",
    "2. create a new `saledate` column which will have only the saledate and remove the time as it is not important for us.\n",
    "3. drop the `saledatetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"saledate\",axis=1,inplace=True)\n",
    "df[\"saledate\"] = pd.to_datetime(df[\"saledatetime\"].dt.date)\n",
    "df.drop(\"saledatetime\",axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to rearrange the columns in the dataframe for better visiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_columns = ['year','make','model','trim','body','transmission','state','condition','color','interior','saledate','seller','sellingprice','mmr','odometer']\n",
    "df = df[rearranged_columns]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5).to_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/009. eda_on_ecommerce_dataset/dataset/output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
