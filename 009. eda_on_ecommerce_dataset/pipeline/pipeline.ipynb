{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">üïµüèª EDA on Vehicle Sales Data üèéÔ∏è</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº ***Introduction***\n",
    "\n",
    "<p style=\"text-align: justify;\">My client company is JJ motors.\n",
    "They are one of the leading car resellers in US.They have provided me a dataset of vehicle sales data. They want to find some business insigts from this dataset so that they can improve they sales in the market.</p>\n",
    "\n",
    "\n",
    "## üßø ***Objective***\n",
    " <p style=\"text-align: justify;\">I will be conducting  Exploratory Data Analysis (EDA) on Vehicle Sales Data dataset and try to get an insights of the dataset. I have some business questions in mind which will help the company in improving their sales. Let's see how we can find the answers to these questions. .I will be loading the dataset and then try to find and any relationships, treands and patterns between among the various features of the dataset. Also, I will be trying to find answers to the below set of questions.</p>\n",
    "\n",
    "**About the data**  \n",
    "This [**dataset**](https://www.kaggle.com/datasets/syedanwarafridi/vehicle-sales-data/code) contains 16 columns of sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Table of Content***\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üí≠ [**My taughts on the dataset**](#thoughts)\n",
    "##### üßπ [**Data Cleaning**](#cleaning)\n",
    "##### ‚ùì [**Business Questions**](#questions)\n",
    "##### üí° **Conclusion**  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Let's go....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library'></a>\n",
    "## ‚¨á <span style=\"color: #20479b; font-weight: bold;\">Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from dateutil import parser\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>  \n",
    "\n",
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">Importing Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/009. eda_on_ecommerce_dataset/dataset/car_prices.csv')\n",
    "\n",
    "print(\"No. of rows.   :\", df.shape[0])\n",
    "print(\"No. of cols.   :\", df.shape[1])  \n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## üó∫Ô∏è <span style=\"color: #20479b; font-weight: bold;\">Exploring the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset into the DataFrame `df`, I will check the `df` shape using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above there are 5558837 rows and 16 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `.info` method to get a shortsummary of the DataFrame. It will include the number of non-null values, Data Types, and Memory Usage etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the \n",
    "- count in the **Non-Null** column is less than the total columns i.e. 558837\n",
    "- that means that there are many NULL values in the dataset. \n",
    "- which we will take care in the data cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `dtypes` attribute to get the datatypes of the columns.  \n",
    "I will also get the same details in `.info()` attribute above. But I like to view it seperately we get a getter understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `df.describe()` \n",
    "- to generate a descriptive statistics of numerical columns of the DataFrame. \n",
    "- It will provide us various functions such as mean, count, Standard Deviation, Min, Max and percentiles.\n",
    "- I have used **Transpose** here as I want the columns of my DataFrame as the index.\n",
    "- This especially helps when I have many numrical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #c81717; font-weight: bold;\">HAS TO BE RE-WRITTEN</span>\n",
    "1. **Year**:\n",
    "   - The dataset spans from the year 1982 to 2015, with the majority of vehicles being sold between 2007 and 2013.\n",
    "   - The average year of sale is approximately 2010, indicating that the dataset predominantly consists of relatively recent vehicle sales.\n",
    "\n",
    "2. **Condition**:\n",
    "   - The condition values range from 1 to 49, with higher values representing better conditions.\n",
    "   - The average condition value is around 30, suggesting that the vehicles in the dataset generally have moderate to good conditions.\n",
    "\n",
    "3. **Odometer**:\n",
    "   - Odometer readings range from 1 to 999,999 miles.\n",
    "   - The average odometer reading is approximately 68,320 miles, indicating that the vehicles vary widely in terms of mileage.\n",
    "   - The median (50th percentile) odometer reading is 52,254 miles, suggesting that half of the vehicles have odometer readings below this value.\n",
    "\n",
    "4. **MMR (Market Median Retail)**:\n",
    "   - MMR values represent the median retail price of vehicles in the market.\n",
    "   - The MMR values range from 25 to 182,000, with an average MMR of approximately 13,769.\n",
    "   - The median MMR is 12,250, indicating that half of the vehicles in the dataset have market median retail prices below this value.\n",
    "\n",
    "5. **Selling Price**:\n",
    "   - Selling prices of vehicles in the dataset range from 1 to 230,000.\n",
    "   - The average selling price is approximately 13,611, suggesting that the dataset contains a mix of vehicles across different price ranges.\n",
    "   - The median selling price is 12,100, indicating that half of the vehicles were sold at prices below this value.\n",
    "\n",
    "Overall, this summary provides valuable insights into the distribution and characteristics of the vehicle sales dataset, including information about the years of sale, vehicle conditions, mileage, market median retail prices, and selling prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check how much percentage of the columns are null. If they are negligible percentage then we can just drop the columns. Otherwise I will fill the na values with the meaninfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in df:\n",
    "    null_percentage[column] = round(( ( df[column].isnull().sum() ) / len(df)) * 100,2)\n",
    "np_df = pd.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the null percentage is negligible when compared to the size of the dataset, we can drop these null columns. The max null percentage is for the column **transmission** i.e. **11.69**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see a lot of unwanted error data here. We have to delete these error data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transmission\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In transmission column I can see that, **nan**, **sedan** and **Sedan** are not data errors, hence we will delete them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see alot of redundent entries here, because data is case sentitive. Hence we can make all small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['make'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thoughts'></a>\n",
    "## üí≠ <span style=\"color: #20479b; font-weight: bold;\">My thoughts on the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my initial Data Exploration,\n",
    "- I can see that the dataset is huge with 558837 columns.\n",
    "- This dataset consits of alot of null values which can be deleted considering the size of the data.\n",
    "- VIN number is unique for each vahicle, hence it is not useful for me, hence I will drop the column.\n",
    "- I also noticed that the datatype of `saledate` column is object, and it also can time and timezone which we may not need.\n",
    "- `state` and `transmission` column has error data, which I can delete.\n",
    "\n",
    "\n",
    "\n",
    "I will be following the below steps to üßπ clean my data for further analysis.\n",
    "1. ‚ùé Drop all the rows containing `null` values.\n",
    "2. ‚ùé Drop columns `VIN`.\n",
    "3. ü™õ Convert the saledate column to Datetime format using `dateutil`.\n",
    "4. ü™õ Make column `make` all smalll.\n",
    "5. ü™õ Replace the make error in make with the standard make name.\n",
    "5. ‚ùé Drop the rows with error data from `state` and `transmission` columns.\n",
    "6. ‚úÖ Re-arrange the columns for better view. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning' ></a>\n",
    "## üßπ <span style=\"color: #20479b; font-weight: bold;\">Data Cleaning</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the null_percentage for each column is negligible. The max is for Transmission is 11.69%, which is negligible when we consider the datasize, i.e. 558837 of data. Hence I will be droping the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIN number is not usefull for my analysis, hence I will be droping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"vin\",axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can also see that sale date is different format. So I am going to use `dateutil.parser` module to clean it and convert it to datetime format. This module will automatically detect varies formats and convert it for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saledatetime']  =    pd.to_datetime(df['saledate' ].apply( parser.parse),utc=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can \n",
    "1. drop the older  `saledate` column, \n",
    "2. create a new `saledate` column which will have only the saledate and remove the time as it is not important for us.\n",
    "3. drop the `saledatetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"saledate\",axis=1,inplace=True)\n",
    "df[\"saledate\"] = pd.to_datetime(df[\"saledatetime\"].dt.date)\n",
    "df.drop(\"saledatetime\",axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will change the `make` column to all small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'] = df['make'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will replace the make names with standard one's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'].replace({'chev truck':'chevrolet','dodge tk':'dodge','ford tk':'ford','ford truck':'ford','gmc truck':'gmc','hyundai tk':'hyundai','land rover':'landrover',\n",
    "                    'mazda tk':'mazda','mercedes-b':'mercedes','mercedes-benz':'mercedes','vw':'volkswagen'},inplace=True)\n",
    "sorted(df['make'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df[ ~df[ 'state'].str.startswith('3vwd'  )]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to rearrange the columns in the dataframe for better visiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_columns = ['year','make','model','trim','body','transmission','state','condition','color','interior','saledate','seller','sellingprice','mmr','odometer']\n",
    "df = df[rearranged_columns]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='questions'></a>  \n",
    "\n",
    "\n",
    "## ‚ùì <span style=\"color: #20479b; font-weight: bold;\">Business Questions</span>\n",
    "\n",
    "Questions\n",
    "1. What is sales propotion of car makers in each state?\n",
    "\n",
    "\n",
    "\n",
    "1. What is the trend in vehicle sales over the years based on the \"year\" column?\n",
    "2. Which vehicle make dominates the sales in the dataset?\n",
    "3. Are there any particular models that consistently perform better in terms of sales?\n",
    "4. How does the distribution of vehicle trims affect their selling prices?\n",
    "5. What body type is most commonly sold in the dataset?\n",
    "6. Is there any correlation between transmission type and selling price?\n",
    "7. Does the VIN (Vehicle Identification Number) have any influence on sales performance?\n",
    "8. Which states contribute the most to overall vehicle sales?\n",
    "9. How does the condition of the vehicle impact its selling price?\n",
    "10. Is there a relationship between odometer reading and selling price?\n",
    "11. Are certain colors more popular among buyers, and do they affect selling prices?\n",
    "12. Does the interior type influence the selling price of a vehicle?\n",
    "13. What type of sellers (e.g., dealerships, private sellers) are more successful in selling vehicles?\n",
    "14. Is there a correlation between the Manheim Market Report (MMR) value and the actual selling price of vehicles?\n",
    "15. How does the sale date (month, day of the week) affect the selling price and volume of vehicle sales?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">1Ô∏è‚É£ What is the sales propotion of car makers in New York(ny) and Texas(tx) for the last 3 years from the data?</span>\n",
    "\n",
    "This question is very important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1 = df.loc[(df['state'].isin(['ny', 'tx'])) & (df['year'] >= (df['year'].max()-3))]\n",
    "data = df_q1.groupby ( ['state' , 'make']).size().reset_index( name ='Sales in Units' )\n",
    "data = data.sort_values(by='make').reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.bar(data, y='make', x='Sales in Units', color='state', orientation='h', title='Sales in Units by Make and State',\n",
    "           labels={'Sales in Units': 'Sales in Units', 'make': 'MAKE', 'state': 'STATE'},barmode='group')\n",
    "fig.update_layout(legend_title_text='State', width=1300, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.loc[(df_q1['state']=='ny') & (df_q1['make']=='acura')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['make','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
