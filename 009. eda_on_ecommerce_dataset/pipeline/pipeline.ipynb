{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">üïµüèª EDA on Vehicle Sales Data üèéÔ∏è</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº **Introduction**\n",
    "\n",
    "<p style=\"text-align: justify;\">They are one of the leading car resellers in the US. They have chosen me as their data scientist so that I can analyze some data for them and give some business insights by which they can improve their sales. They have provided me with a dataset of vehicle sales data. They want to find some business insights from this dataset so that they can improve their sales in the market.</p>\n",
    "\n",
    "## üßø **Objective**\n",
    " <p style=\"text-align: justify;\">The sales of JJ motors have not been very good lately and hence they had to make some very hard business decisions of laying off people in many of their offices. And they are not happy with the performance for the past 4-5 years. Hence they want to study and analyze the market so that they can improve their sales and get back in the business. They have chosen a huge dataset for me, which has details about the car sales until the year 2015.\n",
    "     \n",
    "In their past survey, the people said that their customers were not happy with the options provided by them. So my plan is to focus on the preferences of the customers. This will help me really to get into the minds of the customers and understand what are they looking for in a car they are buying so that my company can use this data to polish their marketing and sales techniques. I will be conducting Exploratory Data Analysis (EDA) on the Vehicle Sales Data dataset and try to get an insight of the dataset. I have some business questions in mind which will help the company in improving their sales. Let's see how we can find the answers to these questions. I will be loading the dataset and then try to find any relationships, trends and patterns between among the various features of the dataset. Also, I will be trying to find answers to the below set of questions.\n",
    " \n",
    " </p>\n",
    "\n",
    "**About the data**  \n",
    "This dataset contains 16 columns. This data set is from Kaggle. You can [**click here**](https://www.kaggle.com/datasets/syedanwarafridi/vehicle-sales-data/code) to view the dataset on kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Table of Content***\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üí≠ [**My taughts on the dataset**](#thoughts)\n",
    "##### üßπ [**Data Cleaning**](#cleaning)\n",
    "##### ‚ùì [**Business Questions**](#questions)\n",
    "##### üí° **Conclusion**  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Let's go....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library'></a>\n",
    "## ‚¨á <span style=\"color: #20479b; font-weight: bold;\">Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnds\n",
    "import numpy as nmpi\n",
    "import matplotlib.pyplot as ppt\n",
    "import seaborn as sbrn\n",
    "import plotly.express as epx\n",
    "%matplotlib inline\n",
    "from dateutil import parser\n",
    "import datetime as dati\n",
    "import plotly.graph_objs as grp_ob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the basic libraries I will be using for this pipeline. I am using pandas for the dataframe, numpy for all the calculations. matplotlib, plotly an seaborn I will be using to plot the graphs to better understand the graph. And I have also used dateutil to clean the datetime columns and covert it into a correct format which cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>  \n",
    "\n",
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">Importing Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pnds.read_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/009. eda_on_ecommerce_dataset/dataset/car_prices.csv')\n",
    "\n",
    "print(\"Dataframe rows.   :\", len(dataset))\n",
    "print(\"Dataframe cols.   :\", len(dataset.columns))  \n",
    "print(\"=\"*27)\n",
    "\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that we have 558837 rows in this dataset. There are 16 columns in total. I can see that there are very insightful data in this dataset. But the data does not look very clean. At this point, I can see VIN columns which I feel like its unnecessary and also `saledate` column does not look in the correct format. It has time zones and all are included in them. I think we might have to clean these columns. But let's explore the dataset further and see what we can do about these columns and others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## üó∫Ô∏è <span style=\"color: #20479b; font-weight: bold;\">Exploring the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset into the DataFrame `dataset`, I will check the `dataset` shape using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above there are 5558837 rows and 16 columns.\n",
    "This is a good start for us a as there is a lot of data for us to analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `.info` method to get a shortsummary of the DataFrame. It will include the number of non-null values, Data Types, and Memory Usage etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the \n",
    "- count in the **Non-Null** column is less than the total columns i.e. 558837\n",
    "- that means that there are many NULL values in the dataset. \n",
    "- which we will take care in the data cleaning part.\n",
    "- Looking at the datatype, I can see that datatype looks fine, except for the saledate column. It is of object datatype. I will change the datatype of this column.\n",
    "- The size of our dataset is arround 68.2 MegaBytes.\n",
    "- There are 3 datatypes in this dataframe i.e. float, int and object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `dtypes` attribute to get the datatypes of the columns.  \n",
    "I will also get the same details in `.info()` attribute above. But I like to view it seperately we get a getter understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get a statistics of the dataframe using describe\n",
    "- It will provide us various functions such as mean, count, Standard Deviation, Min, Max and percentiles.\n",
    "- I have used **Transpose** here as I want the columns of my DataFrame as the index.\n",
    "- This especially helps when I have many numrical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can get very insightful details of the columns. Let's go one column at a time.\n",
    "\n",
    "1. **Year**:\n",
    "   - I can see that this dataset's sales details dated from the year 1982 to 2015.\n",
    "   - Even if the data has old data, the old sales details are not many. The mean column says that rows are mostly around 2010. This means this is comparatively recent data.\n",
    "   - The average year of sale is approximately 2010, indicating that the dataset predominantly consists of relatively recent vehicle sales.\n",
    "\n",
    "2. **Condition**:\n",
    "   - The condition is rated from 1 to 50 in this dataset. 1 being low and 50 being the best condition.\n",
    "   - Average is 30, which means that most vehicles are moderately maintained.\n",
    "\n",
    "4. **Odometer**:\n",
    "   - Based on the average values, it looks like most of the vehicles run for long miles on average they run for 68,320 miles.\n",
    "   The minimum value is 1, which suggests that there are vehicles as well.\n",
    "   - The 50th percentile suggests that half of the vehicles run less than 52,254 miles.\n",
    "\n",
    "5. **MMR (Which stands for Market Median Retail)**:\n",
    "   - There are records for MMR 25 dollars as well, which might be because the vehicle is old or also if it is not maintained well.\n",
    "   - On average, the MMR is around 13000 dollars.\n",
    "   - The median suggests that in half of the data, the MMR is below 12,250 dollars.\n",
    "\n",
    "6. **Selling Price**:\n",
    "   - One thing I noticed something odd is that the minimum selling price is 1 dollar.\n",
    "   - I need to check which records have selling price as 1.\n",
    "   - median values suggest that for almost half of the data, the selling price is less than 12100 dollars.\n",
    "\n",
    "Overall, this summary provides valuable insights into the distribution and characteristics of the vehicle sales dataset, including information about the years of sale, vehicle conditions, mileage, market median retail prices, and selling prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will check if there are any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \"*30)\n",
    "print(\"Dataframe rows :\", len(dataset))\n",
    "print(\" \"*30)\n",
    "print(\"=\"*30)\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check how much percentage of the columns are null. If they are negligible percentage then we can just drop the columns. Otherwise I will fill the na values with the meaninfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in dataset:\n",
    "    null_percentage[column] = round(( ( dataset[column].isnull().sum() ) / len(dataset)) * 100,2)\n",
    "np_dataset = pnds.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the above table, the max null percentage is for the column. Transmission is around 11 per cent. It is difficult to guess the transmision of the cars because there is no engine details in this data. And all the other columns have null percentages less than 3. So if you see the size of the data it is not very huge. And if we start guess and filling the data, we might loose quality in the data. I want to preserve the quality and hence I can drop these rows. And also, \n",
    "\n",
    "As the null percentage is negligible when compared to the size of the dataset, we can drop these null columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me check if there are unwanted records in our dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see a lot of rows with unwanted data here. We have to delete these error data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for transmission column now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"transmission\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally there are two types that are automatic and manual, but in this dataset, I can see that In the transmission column there are, **nan**, **sedan** and **Sedan** entries which are definetly data errors.\n",
    "Now similar to transmission column I think that it is better to drop these columns as we loose the data quality if we fill these entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['make'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In make columns see a lot of entries where the name is same but they are in different case, To better represent the data and study from it will essential for me to clean this data, and connect the make names in the column. I am thinking of making this all small. And also for records where there are additional letters I will replace the columns with standard name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me view the data sorting in alphabetical order, so that I can recognize which are the similar names which I can rename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(dataset['make'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many entries which are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thoughts'></a>\n",
    "## üí≠ <span style=\"color: #20479b; font-weight: bold;\">My thoughts on the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my initial Data Exploration,\n",
    "- I can see that the dataset is huge with 558837 columns.\n",
    "- This dataset consits of alot of null values which can be deleted considering the size of the data.\n",
    "- VIN number is unique for each vahicle, hence it is not useful for me, hence I will drop the column.\n",
    "- I also noticed that the datatype of `saledate` column is object, and it also can time and timezone which we may not need.\n",
    "- `state` and `transmission` column has error data, which I can delete.\n",
    "\n",
    "\n",
    "\n",
    "I will be following the below steps to üßπ clean my data for further analysis.\n",
    "1. ‚ùé Drop all the rows containing `null` values.\n",
    "2. ‚ùé Drop columns `VIN`.\n",
    "3. ü™õ Convert the saledate column to Datetime format.\n",
    "4. ü™õ Add columns `sale_year` and  `sale_month` using the `saledate` column.\n",
    "4. ü™õ Make column `make` all smalll.\n",
    "5. ü™õ Replace the make error in make with the standard make name.\n",
    "5. ‚ùé Drop the rows with error data from `state` and `transmission` columns.\n",
    "6. ‚úÖ Re-arranging the columns for better readablity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning' ></a>\n",
    "## üßπ <span style=\"color: #20479b; font-weight: bold;\">Data Cleaning</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the null_percentage for each column is negligible. The max is for Transmission is 11.69%, which is negligible when we consider the datasize, i.e. 558837 of data. Hence I will be droping the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \"*30)\n",
    "print(\"Dataset rows   :\", len(dataset))\n",
    "print(\"=\"*30)\n",
    "print(\" \"*30)\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to me VIN number will not be useful at all for me because it is unique for all cars. It is better to delete it to reduce teh complexity of the dataset because it's not useful for my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"vin\",axis=1,inplace=True)\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I said before the sale date column in this format is very difficult to work with because if I want to filter the data or sort the data based on date then it will not be possible for me to do it accurately which this format. So I will clean it up using `dateutil.parser` package to clean it and convert it to the right datetime format. This module will automatically detect various formats and convert them for us. I will convert them to utc standard to maintain the uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_standard = parser.parse\n",
    "\n",
    "dataset['saledatetime']  =    pnds.to_datetime( dataset['saledate' ].apply(date_standard), utc=True )\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can \n",
    "1. drop the older  `saledate` column, \n",
    "2. create a new `saledate` column which will have only the saledate and remove the time as it is not important for us.\n",
    "3. drop the `saledatetime`.\n",
    "4. add `sale_date` and `sale_year` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"saledate\",axis=1,inplace=True)\n",
    "dataset[\"saledate\"] = pnds.to_datetime(dataset[\"saledatetime\"].dati.date)\n",
    "dataset.drop(\"saledatetime\",axis=1,inplace=True)\n",
    "dataset['sale_month'] = dataset['saledate'].dati.strftime('%B')\n",
    "dataset['sale_year'] = dataset['saledate'].dati.year\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will change the `make` column to all small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['make'] = dataset['make'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will replace the make names with standard one's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['make'].replace({'chev truck':'chevrolet','dodge tk':'dodge','ford tk':'ford','ford truck':'ford','gmc truck':'gmc','hyundai tk':'hyundai','land rover':'landrover',\n",
    "                    'mazda tk':'mazda','mercedes-b':'mercedes','mercedes-benz':'mercedes','vw':'volkswagen'},inplace=True)\n",
    "sorted(dataset['make'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  dataset[ ~dataset[ 'state'].str.startswith('3vwd'  )]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to rearrange the columns in the dataframe for better visiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_columns = ['year','make','model','trim','body','transmission','state','condition','color','interior','saledate','sale_year','sale_month','seller','sellingprice','mmr','odometer']\n",
    "dataset = dataset[rearranged_columns]\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='questions'></a>  \n",
    "\n",
    "\n",
    "## ‚ùì <span style=\"color: #20479b; font-weight: bold;\">Business Questions</span>\n",
    "\n",
    "Questions\n",
    "1. What is sales propotion of car makers in each state?\n",
    "\n",
    "\n",
    "\n",
    "1. What is the trend in vehicle sales over the years based on the \"year\" column?\n",
    "2. Which vehicle make dominates the sales in the dataset?\n",
    "3. Are there any particular models that consistently perform better in terms of sales?\n",
    "4. How does the distribution of vehicle trims affect their selling prices?\n",
    "5. What body type is most commonly sold in the dataset?\n",
    "6. Is there any correlation between transmission type and selling price?\n",
    "7. Does the VIN (Vehicle Identification Number) have any influence on sales performance?\n",
    "8. Which states contribute the most to overall vehicle sales?\n",
    "9. How does the condition of the vehicle impact its selling price?\n",
    "10. Is there a relationship between odometer reading and selling price?\n",
    "11. Are certain colors more popular among buyers, and do they affect selling prices?\n",
    "12. Does the interior type influence the selling price of a vehicle?\n",
    "13. What type of sellers (e.g., dealerships, private sellers) are more successful in selling vehicles?\n",
    "14. Is there a correlation between the Manheim Market Report (MMR) value and the actual selling price of vehicles?\n",
    "15. How does the sale date (month, day of the week) affect the selling price and volume of vehicle sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">1Ô∏è‚É£ What is the sales propotion of car makers in New York(ny) and Texas(tx) for the last 3 years from the data?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will give them insigts of which car makers are in demand in New York and Texas. \n",
    "2. Further help them to plan out their purchase of second hand cars which are in demand.\n",
    "3. Help them deliver the their customers needs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my q1 i.e. `dataset_q1`.\n",
    "- Here I will filter the data for states NY and TX and where column year is past 3 year of it's max.\n",
    "- I will create another dataset `data` using `dataset_q1`, where I will group the data on `state` and `make` column and also get their count in `Sales in Units` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_q1 = .loc[(['state'].isin(['ny', 'tx'])) & (['year'] >= (['year'].max()-3))]\n",
    "data = dataset_q1.groupby ( ['state' , 'make']).size().reset_index( name ='Sales in Units' )\n",
    "data = data.sort_values(by='make').reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a bar graph for us\n",
    "- `fig` here is our Plotly figure object.\n",
    "- `epx.bar()` is the function we will be using to plot the graph.\n",
    "- `data` is the  we will be using for the figure.\n",
    "- `x` - we need to specify the column we want to plot on x-axis, in this case it's `make`.\n",
    "- `y` - we need to specify the column we want to plot on y-axis, in this case it's `Sales in Units`.\n",
    "- `color` - is based on which the color coding will be done.\n",
    "- `h` - is how we want to plot the bars. In this case h stands for horizontal\n",
    "- `title` is the title of the figure.\n",
    "- `labe's` - are the labels we want for each figure, in my case I have made it all caps for make and State.\n",
    "- `legend_title_text` - is the title we want to set the title of the legend as.\n",
    "- `width` and `height`is the pixel size of the figure. In this case 1300*1200px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=epx.bar(data, y='make', x='Sales in Units', color='state', orientation='h', title='Sales in Units by Make and State',\n",
    "           labels={'Sales in Units': 'Sales in Units', 'make': 'MAKE', 'state': 'STATE'},barmode='group')\n",
    "fig.update_layout(legend_title_text='State', width=1300, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the last 3 years of this datase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">2Ô∏è‚É£ What is the vehicle sales distribution by month for the last 5 years of the data?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will give them insigts of which which months of the year the vehicle purchase is more\n",
    "2. This will help them to plan out the car purchange during these months so that they can provide more options to the buyers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a  for my question 2 i.e. `dataset_q2`. I will filter the data for column year is past 5 year of it's max.\n",
    "- Created a new column `sale_month_no` so that I can sort it based on month no.\n",
    "- Then I am grouping the data based on sale_month, and also getting a count for each month. \n",
    "- Sort the values based on `sale_month_no`.\n",
    "- I will create another  `data` using `dataset_q1`, where I will group the data on `state` and `make` column and also get their count in `Sales in Units` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_q2 = .loc[(['year'] >= (['year'].max()-5))].copy()\n",
    "dataset_q2['sale_month_no'] = dataset_q2['saledate'].dati.month\n",
    "data2 = dataset_q2.groupby ( ['sale_month','sale_month_no']).size().reset_index( name ='Sales in Units' )\n",
    "data2 = data2.sort_values(by='sale_month_no').reset_index(drop=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a bar graph for us\n",
    "- `fig` here is our Plotly figure object.\n",
    "- `epx.bar()` is the function we will be using to plot the graph.\n",
    "- `data` is the  we will be using for the figure.\n",
    "- `x` - we need to specify the column we want to plot on x-axis, in this case it's `make`.\n",
    "- `y` - we need to specify the column we want to plot on y-axis, in this case it's `Sales in Units`.\n",
    "- `color` - is based on which the color coding will be done.\n",
    "- `h` - is how we want to plot the bars. In this case h stands for horizontal\n",
    "- `title` is the title of the figure.\n",
    "- `labe's` - are the labels we want for each figure, in my case I have made it all caps for make and State.\n",
    "- `legend_title_text` - is the title we want to set the title of the legend as.\n",
    "- `width` and `height`is the pixel size of the figure. In this case 1300*1200px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = epx.line(data2, x = 'sale_month', y='Sales in Units', markers=True)\n",
    "fig.update_traces(line={'width': 4})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can in the diagram, the sales of the vehicles are high in the month of January, Febuary and June.\n",
    "- It is just below 80k units in the month of January.\n",
    "- The sales peaks in the month of Febuary by 80k units.\n",
    "- There is a decline in from march to April.\n",
    "- The sales rises in stedily in the month of May and June.\n",
    "- And then there is a decline again.\n",
    "\n",
    "- So, the company can hire more resources for sales so that they can make the maximun out of the customer buying behevious. And they need to be mindful in the month of April and July as the sales is 0 for these months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">3Ô∏è‚É£ Which make and model are better conditioned?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will show us whether make and model have anything to do with the condition of the vehicles.\n",
    "2. We will see which car and model has good condition.\n",
    "3. This will help the company in setting the price of the cars. If a cars condition is better for most of the users means that the car is welll built and hence can be sold for for a higher price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To maintain a standard we will consider the data in which saledate is older than 5 years.\n",
    "- I will first create a  for my question 2 i.e. `dataset_q2`. I will filter the data for column year is past 5 year of it's max.\n",
    "- Created a new column `sale_month_no` so that I can sort it based on month no.\n",
    "- Then I am grouping the data based on sale_month, and also getting a count for each month. \n",
    "- Sort the values based on `sale_month_no`.\n",
    "- I will create another  `data` using `dataset_q1`, where I will group the data on `state` and `make` column and also get their count in `Sales in Units` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_q3 = dataset.loc[(dataset['year'] <= (dataset['year'].max()-5)) & (dataset['make'].isin(['ford','chevrolet','dodge']))].copy()\n",
    "data3 = dataset_q3.groupby ( ['make','state'])['condition'].mean().reset_index( name ='Avg Condition' )\n",
    "data3['Avg Condition'] = data3['Avg Condition'].round()\n",
    "data3 = data3.sort_values(by='make').reset_index(drop=True)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a bar graph for us\n",
    "- `fig` here is our Plotly figure object.\n",
    "- `epx.bar()` is the function we will be using to plot the graph.\n",
    "- `data` is the dataset we will be using for the figure.\n",
    "- `x` - we need to specify the column we want to plot on x-axis, in this case it's `make`.\n",
    "- `y` - we need to specify the column we want to plot on y-axis, in this case it's `Sales in Units`.\n",
    "- `color` - is based on which the color coding will be done.\n",
    "- `h` - is how we want to plot the bars. In this case h stands for horizontal\n",
    "- `title` is the title of the figure.\n",
    "- `labe's` - are the labels we want for each figure, in my case I have made it all caps for make and State.\n",
    "- `legend_title_text` - is the title we want to set the title of the legend as.\n",
    "- `width` and `height`is the pixel size of the figure. In this case 1300*1200px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data = data3.pivot(index='state', columns='make', values='Avg Condition')\n",
    "ppt.figure(figsize=(10, 10))\n",
    "sbrn.heatmap(pivot_data, cmap='coolwarm', annot=True, fmt=\".2f\", linewidths=0.5, vmin= 0 , vmax=50)\n",
    "ppt.title('Mean Condition by Make and Model')\n",
    "ppt.xlabel('Model')\n",
    "ppt.ylabel('Make')\n",
    "ppt.xticks(rotation=45)\n",
    "ppt.yticks(rotation=0)\n",
    "ppt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Pivot the DataFrame to have 'state' as rows, 'make' as columns, and 'Avg Condition' as values\n",
    "pivot_data = data3.pivot(index='state', columns='make', values='Avg Condition')\n",
    "\n",
    "# Create a trace for the heatmap\n",
    "trace = grp_ob.Heatmap(z=pivot_data.values,\n",
    "                   x=pivot_data.columns,\n",
    "                   y=pivot_data.index,\n",
    "                   colorscale='RdBu',  # Choose a colorscale\n",
    "                   colorbar=dict(title='Avg Condition'),\n",
    "                   zmin=0, zmax=50,  # Set the color scale range\n",
    "                   hoverongaps=False,\n",
    "                   text=pivot_data.values,\n",
    "                   hoverinfo='text')\n",
    "\n",
    "# Create the layout\n",
    "layout = grp_ob.Layout(title='Mean Condition by Make and State',\n",
    "                   xaxis=dict(title='Make'),\n",
    "                   yaxis=dict(title='State'))\n",
    "\n",
    "# Create the figure and plot the heatmap\n",
    "fig = grp_ob.Figure(data=[trace], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbrn.scatterplot(data=data3, x=\"make\", y='Avg Condition', hue=\"state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can in the diagram, the sales of the vehicles are high in the month of January, Febuary and June.\n",
    "- It is just below 80k units in the month of January.\n",
    "- The sales peaks in the month of Febuary by 80k units.\n",
    "- There is a decline in from march to April.\n",
    "- The sales rises in stedily in the month of May and June.\n",
    "- And then there is a decline again.\n",
    "\n",
    "- So, the company can hire more resources for sales so that they can make the maximun out of the customer buying behevious. And they need to be mindful in the month of April and July as the sales is 0 for these months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['saledate'].dati.strftime('%B')\n",
    "dataset['saledate'].dati.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">4Ô∏è‚É£ What propotion of SUV sales have been taken up by each vehicle colors?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will show us the color preference of the customers in the market.\n",
    "2. This is will help the company is finding out what color is in demand.\n",
    "3. This is also help them in setting the re-sale price according to the demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my question 4 i.e. `dataset_q4`. I will filter the data for body.\n",
    "- Created a new column `propotion` which will have count of sales for each colors.\n",
    "- I will create another dataset `color_propotion` using `dataset_q4`, where I will devide the column `propotion` by total units to find a percentage.\n",
    "- And then we are going to present it in a form of pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_q4 = dataset.loc[(dataset['body'].str.upper() == 'SUV'),['body','color']].copy()\n",
    "dataset_q4\n",
    "color_propotion = dataset_q4.groupby(['color']).size().reset_index()\n",
    "color_propotion\n",
    "color_propotion['propotion'] = color_propotion[0]\n",
    "color_propotion\n",
    "color_propotion.drop(0,axis=1,inplace=True)\n",
    "total_vehicle_sales = dataset_q4.groupby(['body','color']).size().sum()\n",
    "color_propotion['propotion'] = (color_propotion['propotion']/total_vehicle_sales)*100\n",
    "color_propotion.to_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/009. eda_on_ecommerce_dataset/dataset/output2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a pie chart to represent the color propotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = color_propotion['color']\n",
    "proportion = color_propotion['propotion']\n",
    "ppt.figure(figsize=(10,10))\n",
    "ppt.pie(proportions, labels=colors, autopct='%1.1f%%', startangle=140)\n",
    "ppt.title('Proportion of SUV Sales by Color') \n",
    "ppt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sale of color `black` is the most prominent, constituting of 21.8% of the sales.\n",
    "- Followed by `white` and `silver` which is 17.32% and 15.0% of the sales respectively.\n",
    "- With this pie chart we come to know the color preferences of the users.\n",
    "- This will help the company in developing product, sales and inventory management decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">5Ô∏è‚É£ What is the co-relation between odometer reading and the percentage decrease from selling price to MMR of the car?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will show us whether odometer reading have any connections for the MMR of the car.\n",
    "2. This will help the company to set pricing strategies accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my question 4 i.e. `dataset_q4`. I will filter the data for body.\n",
    "- I will sample only last 200 entries to simply it for us.\n",
    "- Created a new column `propotion` which will have count of sales for each colors.\n",
    "- I will create another dataset `color_propotion` using `dataset_q4`, where I will devide the column `propotion` by total units to find a percentage.\n",
    "- And then we are going to present it in a form of pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_q5 = dataset[['odometer','sellingprice','mmr']].sample(n=200, random_state=42)\n",
    "dataset_q5['price_decrease_percentage'] = round(((dataset['sellingprice'] - dataset['mmr'])/dataset['sellingprice'])*100)\n",
    "dataset_q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a pie chart to represent the color propotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset_q5['odometer']\n",
    "y = dataset_q5['price_decrease_percentage']\n",
    "\n",
    "z = nmpi.polyfit(x,y,1)\n",
    "p = nmpi.poly1d(z)\n",
    "\n",
    "fig = ppt.figure(figsize=(10,10))\n",
    "ab = fig.add_subplot(1,1,1)\n",
    "ab.set_xlabel('odometer')\n",
    "ab.set_ylabel('price_decrease_percentage')\n",
    "\n",
    "ab.scatter(x, y, label='data')\n",
    "\n",
    "ab.plot(x, p(x),color='r',linestyle='dashed',label= 'fit' )\n",
    "ab.legend(loc='upper left')\n",
    "\n",
    "# # ppt.scatter(x,y)\n",
    "# # ppt.show()\n",
    "\n",
    "sbrn.scatterplot(data=dataset_q5, x=\"odometer\", y=\"price_decrease_percentage\", alpha=0.5, s=10)\n",
    "sbrn.plot(x,p(x),)\n",
    "ppt.ylim(0, 40)\n",
    "ppt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression line\n",
    "z = nmpi.polyfit(x, y, 1)\n",
    "p = nmpi.poly1d(z)\n",
    "\n",
    "# Create scatter plot with seaborn\n",
    "sbrn.scatterplot(data=dataset_q5, x=\"odometer\", y=\"price_decrease_percentage\", alpha=0.5, s=10)\n",
    "\n",
    "# Plot the regression line\n",
    "sbrn.lineplot(x=x, y=p(x), color='r', linestyle='dashed', label='fit')\n",
    "\n",
    "# Set y-axis limits\n",
    "ppt.ylim(0, 40)\n",
    "\n",
    "# Show plot\n",
    "ppt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbrn\n",
    "\n",
    "x = dataset_q5['odometer']\n",
    "y = dataset_q5['price_decrease_percentage']\n",
    "\n",
    "ax = sbrn.scatterplot(data=dataset_q5, x=\"odometer\", y=\"price_decrease_percentage\", alpha=0.5, s=10)\n",
    "ax.set_ylim(0, 50)  # Set y-axis limits\n",
    "ppt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
