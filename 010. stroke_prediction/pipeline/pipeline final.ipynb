{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">Stroke Prediction Project</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº **Introduction**\n",
    "\n",
    "<p style=\"text-align: justify;\">I am a data scientist for a company called TrackFit. And it is building an application which tracks the health data for the user. And they are planning to add an additonal function where it will take some inputs and track the body mass index and based on these features it will try to predict whether user has chances of getting a stroke or not. Strokes are one of the many comman cause of deaths. The aim of our company is reduce the number of deaths that are caused due to heart stroke. But giving this stroke prediction function to the user, we are make the user beware of the potential harm and inform him/her to get a doctors opinion at the earliest, which will result is reducing the cause of deaths.</p>\n",
    "\n",
    "\n",
    "## üßø **Objective**\n",
    " <p style=\"text-align: justify;\">Then objective of this project is to build an machine learning module which will predict whether an user has chances of getting a hear stroke. For this my company are given me a dataset which has many metrics which has impact on the cause of stroke. So I will be using these features and building an accurate machine learning model. I have specified the steps we will be following in the **Table of content** so that it will be easier to navigate.\n",
    " \n",
    " </p>\n",
    "\n",
    "**About the data**  \n",
    "This dataset contains 12 columns. This data set is from Kaggle. You can [**click here**](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset) to view the dataset on kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Content**\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üó∫Ô∏è [**Exploring the dataset**](#exploration)\n",
    "##### üí≠ [**My taughts on the dataset**](#thoughts)\n",
    "##### ‚öôÔ∏è [**Pre-processing the data**](#processing)\n",
    "##### üîß [**Feature Engineering**](#feature)\n",
    "##### üóÇÔ∏è [**Model Selection**](#selection)\n",
    "##### ü§ñ [**Model Training**](#model)\n",
    "##### ‚úÖ [**Model Assessment**](#assess)\n",
    "##### üéõÔ∏è [**Hyper-Parameter Tuning**](#tuning)\n",
    "##### üèÅ [**Final Model**](#Final)\n",
    "##### üí° [**Conclusion**](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Let's begin....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library'></a>\n",
    "## ‚¨á <span style=\"color: #20479b; font-weight: bold;\">Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   pandas as  pd\n",
    "import warnings\n",
    "import    numpy as  np\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from    sklearn.preprocessing import   OneHotEncoder\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "from    sklearn.compose import  ColumnTransformer\n",
    "from  imblearn.over_sampling import SMOTE\n",
    "from  sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm  import SVC\n",
    "from sklearn.ensemble   import RandomForestClassifier\n",
    "from sklearn.tree  import   DecisionTreeClassifier   \n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from  sklearn.metrics import roc_auc_score\n",
    "from  sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>  \n",
    "\n",
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">Importing Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/010. stroke_prediction/dataset/healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "print(\"No. of rows.   :\", dataset.shape[0])\n",
    "print(\"No. of cols.   :\", dataset.shape[1])  \n",
    "print(\"=\"*30)\n",
    "\n",
    "dataset.rename( columns = {\n",
    "                                'id':'identity',\n",
    "                                'gender':'sex',\n",
    "                                'hypertension': 'high_blood_pressure',\n",
    "                                'heart_disease':'cardiovascular_disease' ,\n",
    "                                'ever_married':'marrital_status' ,   \n",
    "                                'work_type':'profession' ,\n",
    "                                'Residence_type':'stay',\n",
    "                                'avg_glucose_level':'blood_sugar_level' ,\n",
    "                                'bmi':'body_mass_index' ,\n",
    "                                'smoking_status':'tobaco_use' }\n",
    "                                ,inplace=True)\n",
    "\n",
    "dataset.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have renamed the column for better visiblity and understanding. and then I wwe can see a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## üó∫Ô∏è <span style=\"color: #20479b; font-weight: bold;\">Exploring the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "For EDA and Data Pre-processing I will be using the main datafram. Once dataframe is cleaned. I will be splitting it into `train` and  `test` split. Here's why\n",
    "1. I do not want the just the `test` data to be cleaned and `train` data having unwanted data and error.\n",
    "2. If I clean only the `test` data then my data is not generalized. Hence while my model tries to predict it will have different issues during training and testing.\n",
    "\n",
    "After loading the dataset into the DataFrame `dataset`, I will check the `dataset` shape using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above there are 5110 rows and 12 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check how much percentage of the columns are null. If they are negligible percentage then we can just drop the columns. Otherwise I will fill the na values with the meaninfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in dataset:\n",
    "    null_percentage[column] = round(( ( dataset[column].isnull().sum() ) / len(dataset)) * 100,2)\n",
    "np_df = pd.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the null percentage of column `body_mass_index` is negligible when compared to the size of the dataset, we can drop these null rows as body mass index cannot be `NULL`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.duplicated().any()` I will be checking if there are any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(dataset, x='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to see data for all age groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check why there was data for age less than 1 year old's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[dataset['age']<1].shape)\n",
    "print('='*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 42 rows, and the body mass index looks less. There are chances that these are records for the infants. Let's check if all the records `worktype` is children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[dataset['age']<1].equals(dataset[(dataset['age']<1) & (dataset['profession'] == 'children')]))\n",
    "print('='*30)\n",
    "dataset.loc[dataset['age']<1,['body_mass_index']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can both the dataframes match and also teh body mass index ais less is very less. Hence we I think that records are for infants. So we need not delete these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (p1,p2,p3) = plt.subplots(1,3, figsize=(13, 6), dpi=300)\n",
    "\n",
    "propotion = dataset['high_blood_pressure'].value_counts()\n",
    "names = ['No','Yes']\n",
    "p1.pie(propotion, labels=names, autopct='%1.1f%%')\n",
    "p1.set_title('high_blood_pressure', fontweight='bold')\n",
    "\n",
    "propotion = dataset['cardiovascular_disease'].value_counts()\n",
    "names = ['No','Yes']\n",
    "p2.pie(propotion, labels=names, autopct='%1.1f%%')\n",
    "p2.set_title('Heart Disease', fontweight='bold')\n",
    "\n",
    "propotion = dataset['marrital_status'].value_counts()\n",
    "names = ['No','Yes']\n",
    "p3.pie(propotion, labels=names, autopct='%1.1f%%')\n",
    "p3.set_title('Married', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this above plot you can see that\n",
    "1. **high_blood_pressure:** Only 9.2% of all the people have high_blood_pressure problem.\n",
    "2. **Heart Disease:** About 95.0% of all the people do not have Heart Disease problem.\n",
    "3. **Married:** About 34.7% are married.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['stroke'].value_counts().plot(kind='pie')\n",
    "plt.title('Proportion for stroke column', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that the `data is imbalanced`, specially since we are focussing on stroke detection we have very less data for people you got stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (b1, b2) = plt.subplots(1, 2, figsize=(8, 4), dpi=300)\n",
    "\n",
    "sns.histplot(data=dataset, x=\"blood_sugar_level\", ax=b1)\n",
    "sns.histplot(data=dataset, x=\"body_mass_index\", ax=b2)\n",
    "plt.subplots_adjust(left=0.1, right=0.8, top=0.8, bottom=0.1, wspace=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_of_numerical_cols = dataset.groupby('stroke')[['body_mass_index', 'blood_sugar_level', 'age']].mean().reset_index()\n",
    "names = ['No Stroke',  'Stroke']\n",
    "colors = ['#82b4a2',   '#dd987b']\n",
    "barwidth = 0.4\n",
    "\n",
    "fig, p = plt.subplots(1, 3, figsize=(13, 6), dpi=400)\n",
    "\n",
    "for i, col in enumerate(['body_mass_index', 'blood_sugar_level', 'age']):\n",
    "    x = avg_of_numerical_cols['stroke']\n",
    "    y = avg_of_numerical_cols[col]\n",
    "\n",
    "\n",
    "    p[i].bar(x,  y, label=names,  color =  colors, width =  barwidth, capstyle='round')\n",
    "    p[i].set_title(f'Average {col} for data\\n with stroke and without.', fontweight ='bold', pad  =20)\n",
    "    p[i].set_ylabel(col , fontweight='bold')\n",
    "    p[i].set_xticks(x)\n",
    "    p[i].set_xticklabels(names, fontweight='bold')\n",
    "    p[i].legend(title='Color'  )\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0.0, right=2.4, top=1, bottom=0.1, wspace=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here mainly we need to focus on both üü† `orange` and üü¢ `green` bar.\n",
    "In this graph we try to find relationship between numerical columns and their effect on having stroke. here we learn that\n",
    "\n",
    "Features that `have less impact` on our target label are:\n",
    "1. **body_mass_index**\n",
    "\n",
    "Features which `have significant impact` on our target label are:\n",
    "1. **blood_sugar_level**\n",
    "2. **age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['sex', 'high_blood_pressure', 'cardiovascular_disease', 'marrital_status', 'profession', 'stay']\n",
    "\n",
    "plt.figure(figsize=(25, 18), dpi=400)\n",
    "\n",
    "for index, columns in enumerate(column_names):\n",
    "    plt.subplot(2, 3, index+1)\n",
    "    sns.countplot(y=columns, data=dataset, palette='Set2', hue='stroke')\n",
    "    plt.legend(labels=['No Stroke', 'Stroke'])\n",
    "    plt.title(f'Stroke Count by {columns}', fontweight='bold', pad=20)\n",
    "    plt.ylabel(columns, fontweight='bold')\n",
    "    plt.xlabel('Count', fontweight='bold')\n",
    "    # plt.gca().set_yticklabels(dataset['work_type'], rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(left=0.1, right=1, top=0.6, bottom=0.1, wspace=0.2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # plt.subplot(2, 3, index+1)\n",
    "columns = 'tobaco_use'\n",
    "sns.countplot(y=columns, data=dataset, palette='Set2', hue='stroke')\n",
    "plt.legend(labels=['No Stroke', 'Stroke'])\n",
    "plt.title(f'Stroke Count by {columns}', fontweight='bold', pad=20)\n",
    "plt.ylabel(columns, fontweight='bold')\n",
    "plt.xlabel('Count', fontweight='bold')\n",
    "# plt.gca().set_yticklabels(dataset['profession'], rotation=45)\n",
    "plt.yticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here mainly we need to focus on the üü† `orange` bar.\n",
    "In this graph we try to find relationship between non numerical columns and their effect on having stroke. here we learn that\n",
    "\n",
    "Values look fine here, there are no unwanted/error values.\n",
    "\n",
    "Features that `have less impact` on our target label are:\n",
    "1. **sex**\n",
    "2. **Resident_type**\n",
    "\n",
    "Features which `have significant impact` on our target label are:\n",
    "1. **high_blood_pressure**\n",
    "2. **heart_desease**\n",
    "3. **marrital_status**\n",
    "4. **profession**\n",
    "\n",
    "ü§î Let's confirm this using heatmap of correlation metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation = dataset[['body_mass_index', 'blood_sugar_level', 'age','stroke']]\n",
    "df_cort = df_correlation.corr()\n",
    "sns.heatmap(\n",
    "    df_cort,   annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here if you check against `stroke` and our three numerical columns you can see that value for `age:0.25` and `average_glucose_level:0.13` are more closer to 1 but `body_mass_index:0.042` is significantlly lower. Which confirms our earlier finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thoughts'></a>\n",
    "## üí≠ <span style=\"color: #20479b; font-weight: bold;\">My thoughts on the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my initial Data Exploration,\n",
    "- I can see that the dataset big enough to build a ML model.\n",
    "- This dataset consits of null values in   `body_mass_index` column. Which I can delete it as it negligible rows of data and the body mass index cannot be `null`.\n",
    "- I will be droping column `identity` as we do not need identity column while building a prediction model as will bring the accuracy down.\n",
    "- We do have very less data for people who got stroke than in comparison to people to did not. Which makes it little imbalanced, so I will oversample the data.\n",
    "- columns `body_mass_index`, `sex` and `resident_type` have less impact on the our target label\n",
    "- Having said that the still have slight impact. Hence I will not delete them.\n",
    "- Other than that the data looks pretty clean and I may not have to do a lot of data cleaning.\n",
    "- As I will have to train the model and then later test it, I will be splitting our dataset into two parts. Training and Testing split.\n",
    "\n",
    "\n",
    "Evaluation Metrics:\n",
    "For this dataset I will be using, area under the curve, Accuracy, precision, F1 are the evaluation metrics.\n",
    "\n",
    "\n",
    "\n",
    "Considering all these above points, I will be following the below steps to \n",
    "\n",
    "**‚öôÔ∏è pre-process**\n",
    "1. ‚ùé Drop all the rows containing `null` values\n",
    "2. ‚ùé Drop columns `identity`\n",
    "3. ‚ûó Spliting our main datset into two parts, one part for training and another for testing dataframe\n",
    "    - Doing it before testing or \n",
    "    - to avoid data Scalling and oversampling.\n",
    "\n",
    "**üîß feature Engineer**\n",
    "1. ‚öñÔ∏è Scalling the numerical and categorical labels\n",
    "\n",
    "2. üìà Oversampling the data for stroke = 1, Because of two main reasons.\n",
    "    - Our focus is on stroke detection and data for people who have stroke is very less.\n",
    "    - We do not have to worry about data size as well here, since it's not very huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processing' ></a>\n",
    "## ‚öôÔ∏è <span style=\"color: #20479b; font-weight: bold;\">Pre-processing the data</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ‚ùé Drop all the rows containing `null` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", len(dataset))\n",
    "print(\"=\"*30)\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ‚ùé Drop columns `identity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = dataset.iloc[:,[1,2,3,4,5,6,7,8,9,10,11]]\n",
    "dataset.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ‚ûó Spliting our main datset into two parts, one part for training and another for testing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[:,[0,1,2,3,4,5,6,7,8,9]]\n",
    "# y = dataset.iloc[:,[11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,[0,1,2,3,4,5,6,7,8,9]]\n",
    "y = dataset.iloc[:,[10]]\n",
    "\n",
    "x_train_df,  x_test_df,   y_train_df,  y_test_df = sklearn.model_selection.train_test_split(  x , y  ,  test_size=0.2,  shuffle=True,random_state  =  40)\n",
    "\n",
    "print(\"dataset size      :\",dataset.shape)\n",
    "print(\"x_train_df train size:\",x_train_df.shape)\n",
    "print(\"x_test_df test size :\",x_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature' ></a>\n",
    "## üîß <span style=\"color: #20479b; font-weight: bold;\">Feature Engineering</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ‚öñÔ∏è Scalling the numerical and categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = [ 'age', \n",
    "            'high_blood_pressure', \n",
    "            'cardiovascular_disease', \n",
    "            'blood_sugar_level', \n",
    "            'body_mass_index'\n",
    "            ]\n",
    "col_cat = ['sex', \n",
    "            'marrital_status',  \n",
    "            'profession',  \n",
    "            'stay',  \n",
    "            'tobaco_use'\n",
    "            ]\n",
    "\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "one_hot_enc = sklearn.preprocessing.OneHotEncoder(sparse_output=False, dtype=np.int64)\n",
    "\n",
    "ct = sklearn.compose.ColumnTransformer([('std_scaler', std_scaler,col_num),('one_hot_enc', one_hot_enc,col_cat)],remainder='passthrough')\n",
    "# ,('one_hot_enc', one_hot_enc,col_cat)]\n",
    "ct.fit(   x_train_df )\n",
    "ct.set_output( transform=\"pandas\"  )\n",
    "x_train_df = ct.transform(  x_train_df )\n",
    "x_test_df = ct.transform(   x_test_df )\n",
    "# x_train_df.head(5)\n",
    "\n",
    "x_test_df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. üìà Oversampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_smote =  SMOTE(  )\n",
    "x_train_smot, y_train_smot   =    mod_smote.fit_resample(\n",
    "                                                            x_train_df, \n",
    "                                                            y_train_df)\n",
    "\n",
    "print(\"x_train_smot size :\",x_train_smot.shape)\n",
    "print(\"y_train_smot size :\",y_train_smot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smot = y_train_smot.squeeze()\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smot.value_counts().plot(kind='pie',autopct='%1.0f%%')\n",
    "plt.title('Proportion for stroke column', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is now balanced as it's added synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it had added more synthetic data to our dataset, which is good for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selection'></a>\n",
    "## üóÇÔ∏è <span style=\"color: #20479b; font-weight: bold;\">Model Selection</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I will be trying 5  models\n",
    "1. Linear Regression\n",
    "2. Support Vector Classifier\n",
    "3. Random Forest Classifier\n",
    "4. Xgboost \n",
    "5. KNearestNeighbour\n",
    "\n",
    "I am fitting the model for `x_train_smot` and `y_train_smot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_reg = sklearn.linear_model.LogisticRegression(max_iter=1200)\n",
    "svc = sklearn.svm.SVC(  )\n",
    "ran_for_cls =  sklearn.ensemble.RandomForestClassifier(  random_state = 1200)\n",
    "xg_bst = XGBClassifier(  eval_metric = 'error'  )\n",
    "k_n_n =   sklearn.neighbors.KNeighborsClassifier(    )\n",
    "\n",
    "\n",
    "log_reg.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "svc.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "ran_for_cls.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "xg_bst.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "k_n_n.fit(x_train_smot.values,\n",
    "            y_train_smot.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## ‚úÖ <span style=\"color: #20479b; font-weight: bold;\">Model Assesment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================Logistic Regression==================\n",
    "val_met_list = []\n",
    "\n",
    "y_pred_log_reg = log_reg.predict(\n",
    "                                 x_test_df\n",
    "                                 )\n",
    "val_met_list.append(['Logistic Regression',\n",
    "                      cross_val_score(estimator=log_reg, X=x_train_smot, y=y_train_smot, cv=15).mean(), \n",
    "                      accuracy_score(y_test_df, y_pred_log_reg),\n",
    "                      roc_auc_score(y_test_df, y_pred_log_reg),\n",
    "                      precision_score(y_test_df, y_pred_log_reg),\n",
    "                      f1_score(y_test_df, y_pred_log_reg)])\n",
    "\n",
    "# =============Support Vector Classifier===============\n",
    "\n",
    "y_pred_svc = svc.predict(\n",
    "                         x_test_df\n",
    "                         )\n",
    "val_met_list.append(['Support Vector Classifier',\n",
    "                      cross_val_score(estimator=svc, X=x_train_smot, y=y_train_smot, cv=15).mean(), \n",
    "                      accuracy_score(y_test_df, y_pred_svc),\n",
    "                      roc_auc_score(y_test_df, y_pred_svc),\n",
    "                      precision_score(y_test_df, y_pred_svc),\n",
    "                      f1_score(y_test_df, y_pred_svc)])\n",
    "\n",
    "# ================Random Forest========================\n",
    "\n",
    "y_pred_ran_for_cls = ran_for_cls.predict(\n",
    "                                         x_test_df\n",
    "                                         )\n",
    "val_met_list.append(['Random Forest',\n",
    "                      cross_val_score(estimator=ran_for_cls, X=x_train_smot, y=y_train_smot, cv=15).mean(), \n",
    "                      accuracy_score(y_test_df, y_pred_ran_for_cls),\n",
    "                      roc_auc_score(y_test_df, y_pred_ran_for_cls),\n",
    "                      precision_score(y_test_df, y_pred_ran_for_cls),\n",
    "                      f1_score(y_test_df, y_pred_ran_for_cls)])\n",
    "\n",
    "\n",
    "# =======================Xgboost=========================\n",
    "\n",
    "y_pred_xb = xg_bst.predict(\n",
    "                         x_test_df\n",
    "                         )\n",
    "val_met_list.append(['Xgboost    ',\n",
    "                      cross_val_score(estimator=xg_bst, X=x_train_smot, y=y_train_smot, cv=15).mean(), \n",
    "                      accuracy_score(y_test_df, y_pred_xb),\n",
    "                      roc_auc_score(y_test_df, y_pred_xb),\n",
    "                      precision_score(y_test_df, y_pred_xb),\n",
    "                      f1_score(y_test_df, y_pred_xb)])\n",
    "\n",
    "# ==========================KNN==============================\n",
    "\n",
    "y_pred_knn = k_n_n.predict(\n",
    "                         x_test_df.values\n",
    "                         )\n",
    "val_met_list.append(['KNN   ',\n",
    "                      cross_val_score(estimator=k_n_n, X=x_train_smot.values, y=y_train_smot.values, cv=15).mean(), \n",
    "                      accuracy_score(y_test_df, y_pred_knn),\n",
    "                      roc_auc_score(y_test_df, y_pred_knn),\n",
    "                      precision_score(y_test_df, y_pred_knn),\n",
    "                      f1_score(y_test_df, y_pred_knn)])\n",
    "\n",
    "\n",
    "val_met_df = pd.DataFrame(val_met_list, \n",
    "                          columns=['Model Name','Avg ACC','ACC','AUC','PRE','F1'])\n",
    "val_met_df = val_met_df.sort_values(\n",
    "                                     ascending=False, by=['Avg ACC','ACC','AUC']\n",
    "                                    )\n",
    "val_met_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_list = [log_reg,svc,ran_for_cls,xg_bst,k_n_n]\n",
    "for i, mdl in enumerate(mdl_list):\n",
    "    print(i)\n",
    "    print(mdl)\n",
    "    print(mdl_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_met_list = []\n",
    "\n",
    "\n",
    "log_reg = sklearn.linear_model.LogisticRegression(max_iter=1200)\n",
    "svc = sklearn.svm.SVC(  )\n",
    "ran_for_cls =  sklearn.ensemble.RandomForestClassifier(  random_state = 1200)\n",
    "xg_bst = XGBClassifier(  eval_metric = 'error'  )\n",
    "k_n_n =   sklearn.neighbors.KNeighborsClassifier(    )\n",
    "\n",
    "\n",
    "log_reg.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "svc.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "ran_for_cls.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "xg_bst.fit(x_train_smot,\n",
    "            y_train_smot)\n",
    "k_n_n.fit(x_train_smot.values,\n",
    "            y_train_smot.values)\n",
    "\n",
    "\n",
    "mdl_list = [log_reg,svc,ran_for_cls,xg_bst,k_n_n]\n",
    "\n",
    "for i, mdl in enumerate(mdl_list):\n",
    "\n",
    "\n",
    "    if mdl==k_n_n:\n",
    "        x_train_smot_val = x_train_smot.values\n",
    "        y_train_smot_val = y_train_smot.values\n",
    "        x_test_df_val    = x_test_df.values\n",
    "    else:\n",
    "        x_train_smot_val = x_train_smot\n",
    "        y_train_smot_val = y_train_smot\n",
    "        x_test_df_val    = x_test_df\n",
    "\n",
    "    y_pred_df = log_reg.predict(\n",
    "                                x_test_df_val\n",
    "                                )\n",
    "\n",
    "    val_met_list.append([ mdl_list[i],\n",
    "                        cross_val_score(estimator=mdl, X=x_train_smot_val, y=y_train_smot_val, cv=15).mean(), \n",
    "                        accuracy_score(y_test_df, y_pred_df),\n",
    "                        roc_auc_score(y_test_df, y_pred_df),\n",
    "                        precision_score(y_test_df, y_pred_df),\n",
    "                        f1_score(y_test_df, y_pred_df)])\n",
    "\n",
    "\n",
    "val_met_df = pd.DataFrame(val_met_list, \n",
    "                        columns=['Model Name','Avg ACC','ACC','AUC','PRE','F1'])\n",
    "val_met_df = val_met_df.sort_values(\n",
    "                                    ascending=False, by=['Avg ACC','ACC','AUC']\n",
    "                                    )\n",
    "val_met_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per our valuation metrics the best model out of them are\n",
    "1. Random Forest\n",
    "2. Xgboost\n",
    "\n",
    "Let us try to tune these two models and try to find we can get the model to perform even better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tuning'></a>\n",
    "## üéõÔ∏è <span style=\"color: #20479b; font-weight: bold;\">Hyper-Parameter Tuning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will using gridsearchcv and passing it multiple values so that it can choose a best value for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\" font-weight: bold;\">Random Forest Classifier</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion':['gini', 'log_loss'],'n_estimators':[60,80,100,120,140],  'random_state' : [1200,None]}\n",
    "param_result_list = []\n",
    "grid_ser_cv = GridSearchCV(ran_for_cls,params,cv=5)\n",
    "grid_ser_cv.fit(x_train_smot,y_train_smot)\n",
    "df_results = pd.DataFrame(grid_ser_cv.cv_results_)\n",
    "param_result_list.append([grid_ser_cv.best_score_,grid_ser_cv.best_params_])\n",
    "\n",
    "param_result_df = pd.DataFrame(param_result_list, columns=['best_score_','best_params_',])\n",
    "param_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\" font-weight: bold;\">Support Vector Classifier</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'booster':['gbtree', 'gblinear', 'dart'],'eta':[0.1,0.2,0.3,0.4]}\n",
    "param_result_list = []\n",
    "grid_ser_cv = GridSearchCV(xg_bst,params,cv=5)\n",
    "grid_ser_cv.fit(x_train_smot,y_train_smot)\n",
    "df_results = pd.DataFrame(grid_ser_cv.cv_results_)\n",
    "param_result_list.append([grid_ser_cv.best_score_,grid_ser_cv.best_params_])\n",
    "\n",
    "param_result_df = pd.DataFrame(param_result_list, columns=['best_score_','best_params_',])\n",
    "param_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the scores of `random_forect_classifier` and `svm` model, we can come to a conclusion that both are a great model for this dataset.  \n",
    "Having said that `random_forect_classifier` model perfomed sligtly better. Hence I willl choose that as my final model with `{'criterion': 'gini', 'n_estimators': 140, 'random_state': None}` as the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Final'></a>\n",
    "## üèÅ <span style=\"color: #20479b; font-weight: bold;\">Final Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ran_for_cls =  sklearn.ensemble.RandomForestClassifier(criterion= 'gini', n_estimators= 140,  random_state = None)\n",
    "final_ran_for_cls.fit(x_train_smot,\n",
    "            y_train_smot\n",
    "            )\n",
    "y_pred_ran_for_cls = final_ran_for_cls.predict(\n",
    "                                         x_test_df\n",
    "                                         )\n",
    "print('Logistic Regression')\n",
    "print('='*53)\n",
    "print('Average Accuray -->',cross_val_score(estimator=log_reg, X=x_train_smot, y=y_train_smot, cv=5).mean())\n",
    "print('Accuracy --------->',accuracy_score(y_test_df, y_pred_ran_for_cls))\n",
    "print('ROC_AUS ---------->',roc_auc_score(y_test_df, y_pred_ran_for_cls))\n",
    "print('Precision -------->',precision_score(y_test_df, y_pred_ran_for_cls))\n",
    "print('F1 --------------->',f1_score(y_test_df, y_pred_ran_for_cls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## üí° <span style=\"color: #20479b; font-weight: bold;\">Conclusion</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize everythin we did\n",
    "- we started with loading the dataset\n",
    "- In our eda we noticed that\n",
    "    - identity column was unnessary.\n",
    "    - body_mass_index column had null values.\n",
    "    - dataset was pretty imbalanced.\n",
    "- cleaned the data, by deleting null rows, dropping identity column, and split the data to avoid data leakage.\n",
    "- And then we scaled the numerical and categorical values.\n",
    "- oversampled the data using smote.\n",
    "\n",
    "I tried 5 different model. Out of which `random forest classifier` and `xgboost` model performed the best.  \n",
    "I tuned tuned the hyper parameters using `gridsearchCV` and found that amond both the models, `random forest classifier` outperformed `xgboost` slightly.\n",
    "\n",
    "As per the valuation metrics I  found `random forest classifier` with `{'C': 1.4, 'degree': 4, 'kernel': 'poly'}` parameters provided the best with pretty good acccuracy of 93%.\n",
    "\n",
    "With this model in place, now my company can use this model to take inputs from the users and prompt them if there are chances of getting a stroke for them. This solves the problem that we stated before. This will significantly help the users in reducing the rist of strokes, and notify them to get medical help as soon as possible.\n",
    "\n",
    "I felt that if the data has more parametrics we could have improved more. Also `body_mass_index` of a person does impact on the chances of getting an stroke, but in this dataset it did not show the signs of it. Hence it will be better if data collection is done even more accurately to improve the accuracy of the model.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
