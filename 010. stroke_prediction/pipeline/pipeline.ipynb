{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">Stroke Prediction Project</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº ***Introduction***\n",
    "\n",
    "<p style=\"text-align: justify;\">I am a data scientist for a company called TrackFit. And it is building an application which tracks the health data for the user. And they are planning to add an additonal function where it will take some inputs and track the bmi and based on these features it will try to predict whether user has chances of getting a stroke or not. Strokes are one of the leading cause of deaths all round the world. The aim of our company is reduce the number of deaths that are caused due to heart stroke. But giving this stroke prediction function to the user, we are make the user beware of the potential harm and inform him/her to get a doctors opinion at the earliest, which will result is reducing the cause of deaths.</p>\n",
    "\n",
    "\n",
    "## üßø ***Objective***\n",
    " <p style=\"text-align: justify;\">Then objective of this project is to build an machine  learning module which will predict whether an user has chances of getting a hear stroke. For this my company are given me a dataset which has many metrics which has impact on the cause of stroke. So I will be using these features and building an accurate machine learning model. I have specified the steps we will be following in the **Table of content** so that it will be easier to navigate.\n",
    " \n",
    " I have considered this as a machine learning task as we will in involved the likelyhood of an indivisual having stroke or not based on the data sample. We will be deviding this data into two parts.  \n",
    " </p>\n",
    "\n",
    "**About the data**  \n",
    "This [**dataset**](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset) contains 16 columns of sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Table of Content***\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üó∫Ô∏è [**Exploring the dataset**](#exploration)\n",
    "##### üí≠ [**My taughts on the dataset**](#thoughts)\n",
    "##### ‚öôÔ∏è [**Pre-processing the data**](#processing)\n",
    "##### üîß [**Feature Engineering**](#feature)\n",
    "##### ü§ñ [**Model Training**](#model)\n",
    "##### ‚úÖ [**Model Assessment**](#assess)\n",
    "##### üí° [**Conclusion**](#conclusion)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Let's begin....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library'></a>\n",
    "## ‚¨á <span style=\"color: #20479b; font-weight: bold;\">Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "%matplotlib inline\n",
    "# from dateutil import parser\n",
    "# import datetime as dt\n",
    "# import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.ticker as ticker\n",
    "# import matplotlib.patheffects as path_effects\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>  \n",
    "\n",
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">Importing Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/010. stroke_prediction/dataset/healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "print(\"No. of rows.   :\", df.shape[0])\n",
    "print(\"No. of cols.   :\", df.shape[1])  \n",
    "print(\"=\"*30)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## üó∫Ô∏è <span style=\"color: #20479b; font-weight: bold;\">Exploring the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "For EDA and Data Pre-processing I will be using the main datafram. Once dataframe is cleaned. I will be splitting it into `train` and  `test` split. Here's why\n",
    "1. I do not want the just the `test` data to be cleaned and `train` data having unwanted data and error.\n",
    "2. If I clean only the `test` data then my data is not generalized. Hence while my model tries to predict it will have different issues during training and testing.\n",
    "\n",
    "After loading the dataset into the DataFrame `df`, I will check the `df` shape using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above there are 5110 rows and 12 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `.info` method to get a shortsummary of the DataFrame. It will include the number of non-null values, Data Types, and Memory Usage etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the \n",
    "- count in the **Non-Null** column is less than the total rows for columns `bmi` i.e. 5110\n",
    "- that means that there are many NULL values in the dataset. \n",
    "- which we will take care in the data cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `dtypes` attribute to get the datatypes of the columns.  \n",
    "I will also get the same details in `.info()` attribute above. But I like to view it seperately we get a getter understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `df.describe()` \n",
    "- to generate a descriptive statistics of numerical columns of the DataFrame. \n",
    "- It will provide us various functions such as mean, count, Standard Deviation, Min, Max and percentiles.\n",
    "- I have used **Transpose** here as I want the columns of my DataFrame as the index.\n",
    "- This especially helps when I have many numrical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **age**:\n",
    "   - As we can see here we have data from the age of 0.8 to 82 years.\n",
    "   - Average age is near 43 years.\n",
    "   - MIN is 0.08, we will have to check why there is entry below 1.\n",
    "\n",
    "2. **hypertension**:\n",
    "   - The hypertension values ranges between 0 and 1. 0 means no hypertension 1 means person has hypertension.\n",
    "   - Average values of this colum in 0.09 which means that not many people have hypertension.\n",
    "\n",
    "3. **heart_disease**:\n",
    "   - Average values of this colum in 0.05 which means that not many people have heart disease.\n",
    "\n",
    "4. **avg_glucose_level**:\n",
    "   - The average glucose level of people in this data ranges between 55 to 271 mmol/L.\n",
    "   - Mean is 106 mmol/L.\n",
    "\n",
    "5. **bmi**:\n",
    "   - bmi is ranging from 10 to 97 bmi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will check now many null values are there in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check how much percentage of the columns are null. If they are negligible percentage then we can just drop the columns. Otherwise I will fill the na values with the meaninfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in df:\n",
    "    null_percentage[column] = round(( ( df[column].isnull().sum() ) / len(df)) * 100,2)\n",
    "np_df = pd.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the null percentage of column `bmi` is negligible when compared to the size of the dataset, we can drop these null rows as bmi cannot be `NULL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"gender\"].unique())\n",
    "print(df[\"work_type\"].unique())\n",
    "print(df[\"Residence_type\"].unique())\n",
    "print(df[\"smoking_status\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values look fine here, there are no unwanted/error values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.duplicated().any()` I will be checking if there are any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x='age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to see data for all age groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check why there was data for age less than 1 year old's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['age']<1].shape)\n",
    "print('='*30)\n",
    "df[df['age']<1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 42 rows, and the bmi looks less. There are chances that these are records for the infants. Let's check if all the records `worktype` is children."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['age']<1].equals(df[(df['age']<1) & (df['work_type'] == 'children')]))\n",
    "print('='*30)\n",
    "df.loc[df['age']<1,['bmi']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can both the dataframes match and also teh bmi ais less is very less. Hence we I think that records are for infants. So we need not delete these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (p1,p2,p3) = plt.subplots(1,3, figsize=(13, 6), dpi=300)\n",
    "\n",
    "propotion = df['hypertension'].value_counts()\n",
    "names = ['No','Yes']\n",
    "p1.pie(propotion, labels=names, autopct='%1.1f%%')\n",
    "p1.set_title('Hypertension', fontweight='bold')\n",
    "\n",
    "propotion = df['heart_disease'].value_counts()\n",
    "names = ['No','Yes']\n",
    "p2.pie(propotion, labels=names, autopct='%1.1f%%')\n",
    "p2.set_title('Heart Disease', fontweight='bold')\n",
    "\n",
    "propotion = df['ever_married'].value_counts()\n",
    "names = ['No','Yes']\n",
    "p3.pie(propotion, labels=names, autopct='%1.1f%%')\n",
    "p3.set_title('Married', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this above plot you can see that\n",
    "1. **Hypertension:** Only 9.2% of all the people have Hypertension problem.\n",
    "2. **Heart Disease:** About 95.0% of all the people do not have Heart Disease problem.\n",
    "3. **Married:** About 34.7% are married.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stroke'].value_counts().plot(kind='pie')\n",
    "plt.title('Proportion for stroke column', fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that the `data is imbalanced`, specially since we are focussing on stroke detection we have very less data for people you got stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), dpi=300)\n",
    "\n",
    "sns.histplot(data=df, x=\"avg_glucose_level\", ax=ax1)\n",
    "sns.histplot(data=df, x=\"bmi\", ax=ax2)\n",
    "plt.subplots_adjust(left=0.1, right=0.8, top=0.8, bottom=0.1, wspace=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_of_numerical_cols = df.groupby('stroke')[['bmi', 'avg_glucose_level', 'age']].mean().reset_index()\n",
    "names = ['No Stroke',  'Stroke']\n",
    "colors = ['#82b4a2',   '#dd987b']\n",
    "barwidth = 0.4\n",
    "\n",
    "fig, p = plt.subplots(1, 3, figsize=(13, 6), dpi=400)\n",
    "\n",
    "for i, col in enumerate(['bmi', 'avg_glucose_level', 'age']):\n",
    "    x = avg_of_numerical_cols['stroke']\n",
    "    y = avg_of_numerical_cols[col]\n",
    "\n",
    "\n",
    "    p[i].bar(x,  y, label=names,  color =  colors, width =  barwidth, capstyle='round')\n",
    "    p[i].set_title(f'Average {col} for data\\n with stroke and without.', fontweight ='bold', pad  =20)\n",
    "    p[i].set_ylabel(col , fontweight='bold')\n",
    "    p[i].set_xticks(x)\n",
    "    p[i].set_xticklabels(names, fontweight='bold')\n",
    "    p[i].legend(title='Color'  )\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0.0, right=2.4, top=1, bottom=0.1, wspace=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here mainly we need to focus on both üü† `orange` and üü¢ `green` bar.\n",
    "In this graph we try to find relationship between numerical columns and their effect on having stroke. here we learn that\n",
    "\n",
    "Features that `have less impact` on our target label are:\n",
    "1. **bmi**\n",
    "\n",
    "Features which `have significant impact` on our target label are:\n",
    "1. **avg_glucose_level**\n",
    "2. **age**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type']\n",
    "\n",
    "plt.figure(figsize=(25, 18), dpi=400)\n",
    "\n",
    "for index, columns in enumerate(column_names):\n",
    "    plt.subplot(2, 3, index+1)\n",
    "    sns.countplot(y=columns, data=df, palette='Set2', hue='stroke')\n",
    "    plt.legend(labels=['No Stroke', 'Stroke'])\n",
    "    plt.title(f'Stroke Count by {columns}', fontweight='bold', pad=20)\n",
    "    plt.ylabel(columns, fontweight='bold')\n",
    "    plt.xlabel('Count', fontweight='bold')\n",
    "    # plt.gca().set_yticklabels(df['work_type'], rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.subplots_adjust(left=0.1, right=1, top=0.6, bottom=0.1, wspace=0.2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here mainly we need to focus on the üü† `orange` bar.\n",
    "In this graph we try to find relationship between non numerical columns and their effect on having stroke. here we learn that\n",
    "\n",
    "Features that `have less impact` on our target label are:\n",
    "1. **gender**\n",
    "2. **Resident_type**\n",
    "\n",
    "Features which `have significant impact` on our target label are:\n",
    "1. **hypertension**\n",
    "2. **heart_desease**\n",
    "3. **ever_married**\n",
    "4. **work_type**\n",
    "\n",
    "ü§î Let's confirm this using heatmap of correlation metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correlation = df[['bmi', 'avg_glucose_level', 'age','stroke']]\n",
    "corr = df_correlation.corr()\n",
    "sns.heatmap(corr,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here if you check against `stroke` and our three numerical columns you can see that value for `age:0.25` and `average_glucose_level:0.13` are more closer to 1 but `bmi:0.042` is significantlly lower. Which confirms our earlier finding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thoughts'></a>\n",
    "## üí≠ <span style=\"color: #20479b; font-weight: bold;\">My thoughts on the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my initial Data Exploration,\n",
    "- I can see that the dataset big enough to build a ML model.\n",
    "- This dataset consits of null values in   `bmi` column. Which I can delete it as it negligible rows of data and the bmi cannot be `null`.\n",
    "- I will be droping column `id` as we do not need identity column while building a prediction model as will bring the accuracy down.\n",
    "- We do have very less data for people who got stroke than in comparison to people to did not. Which makes it little imbalanced, so I will oversample the data.\n",
    "- columns `bmi`, `gender` and `resident_type` have less impact on the our target label\n",
    "- Having said that the still have slight impact. Hence I will not delete them.\n",
    "- Other than that the data looks pretty clean and I may not have to do a lot of data cleaning.\n",
    "- As I will have to train the model and then later test it, I will be splitting the data into two parts. Train and Test split.\n",
    "\n",
    "\n",
    "\n",
    "Considering all these above points, I will be following the below steps to \n",
    "\n",
    "**‚öôÔ∏è pre-process**\n",
    "1. ‚ùé Drop all the rows containing `null` values\n",
    "2. ‚ùé Drop columns `id`\n",
    "3. ‚ûó Split train and test data\n",
    "    - Doing it before testing or \n",
    "    - to avoid data Scalling and oversampling.\n",
    "\n",
    "**üîß feature Engineer**\n",
    "1. ‚öñÔ∏è Scalling the numerical and categorical labels\n",
    "\n",
    "2. üìà Oversampling the data for stroke = 1, Because of two main reasons.\n",
    "    - Our focus is on stroke detection and data for people who have stroke is very less.\n",
    "    - We do not have to worry about data size as well here, since it's not very huge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processing' ></a>\n",
    "## ‚öôÔ∏è <span style=\"color: #20479b; font-weight: bold;\">Pre-processing the data</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ‚ùé Drop all the rows containing `null` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ‚ùé Drop columns `id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"id\",axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ‚ûó Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['stroke'],axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x,y,test_size=0.25,shuffle=True)\n",
    "\n",
    "print(\"df size      :\",df.shape)\n",
    "print(\"df train size:\",x_train.shape)\n",
    "print(\"df test size :\",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature' ></a>\n",
    "## üîß <span style=\"color: #20479b; font-weight: bold;\">Feature Engineering</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ‚öñÔ∏è Scalling the numerical and categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = x_train.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "print(col_num)\n",
    "col_cat = x_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(col_cat)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.StandardScaler()\n",
    "one_hot_enc = sklearn.preprocessing.OneHotEncoder(sparse_output=False, dtype=np.int64)\n",
    "\n",
    "ct = sklearn.compose.ColumnTransformer([('std_scaler', std_scaler,col_num),('one_hot_enc', one_hot_enc,col_cat)],remainder='passthrough')\n",
    "ct.fit(x_train)\n",
    "ct.set_output(transform=\"pandas\")\n",
    "x_train = ct.transform(x_train)\n",
    "x_test = ct.transform(x_test)\n",
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. üìà Oversampling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_smote = SMOTE(random_state=42)\n",
    "x_train_smot, y_train_smot = mod_smote.fit_resample(x_train,y_train)\n",
    "\n",
    "print(\"x_train_smot size:\",x_train_smot.shape)\n",
    "print(\"y_train_smot size :\",y_train_smot.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "## ü§ñ <span style=\"color: #20479b; font-weight: bold;\">Model Training</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = sklearn.linear_model.LogisticRegression()\n",
    "svc = sklearn.svm.SVC()\n",
    "ran_for_cls =  sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "\n",
    "log_reg.fit(x_train,y_train)\n",
    "log_reg.predict(x_test)\n",
    "\n",
    "svc.fit(x_train,y_train)\n",
    "svc.predict(x_test)\n",
    "\n",
    "ran_for_cls.fit(x_train,y_train)\n",
    "ran_for_cls.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I will be using 3 models\n",
    "1. Linear Regression\n",
    "2. Support Vector Classifier\n",
    "3. Random Forest Classifier\n",
    "\n",
    "I am fitting the model for `x_trian` and `y_train`\n",
    "Then, predicting target label for the `x_test` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## ‚úÖ <span style=\"color: #20479b; font-weight: bold;\">Model Assesment</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log_reg = log_reg.predict(x_test)\n",
    "result_log_reg = sklearn.metrics.classification_report(y_test,y_pred_log_reg)\n",
    "print('Logistic Regression')\n",
    "print('='*53)\n",
    "print(result_log_reg)\n",
    "\n",
    "y_pred_svc = svc.predict(x_test)\n",
    "result_svc = sklearn.metrics.classification_report(y_test,y_pred_svc)\n",
    "print('Support Vector Classifier')\n",
    "print('='*53)\n",
    "print(result_svc)\n",
    "\n",
    "y_pred_ran_for_cls = ran_for_cls.predict(x_test)\n",
    "result_ran_for_cls = sklearn.metrics.classification_report(y_test,y_pred_ran_for_cls)\n",
    "print('Random Forest Classifier')\n",
    "print('='*53)\n",
    "print(result_ran_for_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will compare the all models and try to select the best model out of the three\n",
    "1. Accuracy for all three model is 0.96.\n",
    "2. We can't just rely on the accuracy score.\n",
    "3. Precision score is best in Logistic Regression model.\n",
    "4. Also if you check the weighted avg and macro avg we can confirm that in this case `Logistic regression model performed the best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tune some hyper parameters and try to find the best performing parameters for this model.  \n",
    "I will use scikit learn `GridSearchCV`.  \n",
    "I will also set the cross validation param to 5 as I want it to cross validate the values 6 times and give me an average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':[0.1, 0.5, 1, 5, 10], 'penalty':('l2',None)}\n",
    "grid_ser_cv = GridSearchCV(log_reg,params,cv=5,return_train_score=False)\n",
    "grid_ser_cv.fit(x_train,y_train)\n",
    "df_results = pd.DataFrame(grid_ser_cv.cv_results_)\n",
    "df_results[['param_C','param_penalty','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selecting the best parameters out of all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ser_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the models with the best params and without parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_hp = sklearn.linear_model.LogisticRegression(C=0.1, penalty= 'l2')\n",
    "\n",
    "\n",
    "log_reg_hp.fit(x_train,y_train)\n",
    "log_reg_hp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log_reg_hp = log_reg_hp.predict(x_test)\n",
    "result_log_reg_hp = sklearn.metrics.classification_report(y_test,y_pred_log_reg_hp)\n",
    "print('Logistic Regression with hyperparameter')\n",
    "print('='*53)\n",
    "print(result_log_reg_hp)\n",
    "\n",
    "\n",
    "print('Logistic Regression without hyperparameter')\n",
    "print('='*53)\n",
    "print(result_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that performance has decreased instead of inscrease. Hence the best params are the defaults one's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## üí° <span style=\"color: #20479b; font-weight: bold;\">Conclusion</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to build a very good "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
