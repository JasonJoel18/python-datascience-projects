{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 style=\"text-align: center;\">üïµüèª Stroke Prediction Project üèéÔ∏è</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº ***Introduction***\n",
    "\n",
    "<p style=\"text-align: justify;\">I am a data scientist for a company called TrackFit. And it is building an application which tracks the health data for the user. And they are planning to add an additonal function where it will take some inputs and track the bmi and based on these features it will try to predict whether user has chances of getting a stroke or not. Strokes are one of the leading cause of deaths all round the world. The aim of our company is reduce the number of deaths that are caused due to heart stroke. But giving this stroke prediction function to the user, we are make the user beware of the potential harm and inform him/her to get a doctors opinion at the earliest, which will result is reducing the cause of deaths.</p>\n",
    "\n",
    "\n",
    "## üßø ***Objective***\n",
    " <p style=\"text-align: justify;\">Then objective of this project is to build an machine  learning module which will predict whether an user has chances of getting a hear stroke. For this my company are given me a dataset which has many metrics which has impact on the cause of stroke. So I will be using these features and building an accurate machine learning model. I have specified the steps we will be following in the **Table of content** so that it will be easier to navigate.\n",
    " \n",
    " I have considered this as a machine learning task as we will in involved the likelyhood of an indivisual having stroke or not based on the data sample. We will be deviding this data into two parts.  \n",
    " </p>\n",
    "\n",
    "**About the data**  \n",
    "This [**dataset**](https://www.kaggle.com/datasets/syedanwarafridi/vehicle-sales-data/code) contains 16 columns of sales data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Table of Content***\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üó∫Ô∏è [**Exploring the dataset**](#exploration)\n",
    "##### üí≠ [**My taughts on the dataset**](#thoughts)\n",
    "##### üßπ [**Data Cleaning**](#cleaning)\n",
    "##### ‚öôÔ∏è [**Data Pre-processing**](#processing)\n",
    "##### ü§ñ [**Feature Engineering**](#processing)\n",
    "##### ü§ñ [**Model Training**](#processing)\n",
    "##### ‚úÖ [**Model Assessment**](#processing)\n",
    "##### üí° **Conclusion**  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Let's go....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library'></a>\n",
    "## ‚¨á <span style=\"color: #20479b; font-weight: bold;\">Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from dateutil import parser\n",
    "import datetime as dt\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>  \n",
    "\n",
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">Importing Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/010. stroke_prediction/dataset/healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "print(\"No. of rows.   :\", df.shape[0])\n",
    "print(\"No. of cols.   :\", df.shape[1])  \n",
    "print(\"=\"*30)\n",
    "\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## üó∫Ô∏è <span style=\"color: #20479b; font-weight: bold;\">Exploring the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset into the DataFrame `df`, I will check the `df` shape using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above there are 5558837 rows and 16 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `.info` method to get a shortsummary of the DataFrame. It will include the number of non-null values, Data Types, and Memory Usage etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that the \n",
    "- count in the **Non-Null** column is less than the total columns i.e. 558837\n",
    "- that means that there are many NULL values in the dataset. \n",
    "- which we will take care in the data cleaning part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `dtypes` attribute to get the datatypes of the columns.  \n",
    "I will also get the same details in `.info()` attribute above. But I like to view it seperately we get a getter understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use `df.describe()` \n",
    "- to generate a descriptive statistics of numerical columns of the DataFrame. \n",
    "- It will provide us various functions such as mean, count, Standard Deviation, Min, Max and percentiles.\n",
    "- I have used **Transpose** here as I want the columns of my DataFrame as the index.\n",
    "- This especially helps when I have many numrical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #c81717; font-weight: bold;\">HAS TO BE RE-WRITTEN</span>\n",
    "1. **Year**:\n",
    "   - The dataset spans from the year 1982 to 2015, with the majority of vehicles being sold between 2007 and 2013.\n",
    "   - The average year of sale is approximately 2010, indicating that the dataset predominantly consists of relatively recent vehicle sales.\n",
    "\n",
    "2. **Condition**:\n",
    "   - The condition values range from 1 to 49, with higher values representing better conditions.\n",
    "   - The average condition value is around 30, suggesting that the vehicles in the dataset generally have moderate to good conditions.\n",
    "\n",
    "3. **Odometer**:\n",
    "   - Odometer readings range from 1 to 999,999 miles.\n",
    "   - The average odometer reading is approximately 68,320 miles, indicating that the vehicles vary widely in terms of mileage.\n",
    "   - The median (50th percentile) odometer reading is 52,254 miles, suggesting that half of the vehicles have odometer readings below this value.\n",
    "\n",
    "4. **MMR (Market Median Retail)**:\n",
    "   - MMR values represent the median retail price of vehicles in the market.\n",
    "   - The MMR values range from 25 to 182,000, with an average MMR of approximately 13,769.\n",
    "   - The median MMR is 12,250, indicating that half of the vehicles in the dataset have market median retail prices below this value.\n",
    "\n",
    "5. **Selling Price**:\n",
    "   - Selling prices of vehicles in the dataset range from 1 to 230,000.\n",
    "   - The average selling price is approximately 13,611, suggesting that the dataset contains a mix of vehicles across different price ranges.\n",
    "   - The median selling price is 12,100, indicating that half of the vehicles were sold at prices below this value.\n",
    "\n",
    "Overall, this summary provides valuable insights into the distribution and characteristics of the vehicle sales dataset, including information about the years of sale, vehicle conditions, mileage, market median retail prices, and selling prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going to check how much percentage of the columns are null. If they are negligible percentage then we can just drop the columns. Otherwise I will fill the na values with the meaninfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in df:\n",
    "    null_percentage[column] = round(( ( df[column].isnull().sum() ) / len(df)) * 100,2)\n",
    "np_df = pd.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the null percentage is negligible when compared to the size of the dataset, we can drop these null columns. The max null percentage is for the column **transmission** i.e. **11.69**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"state\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see a lot of unwanted error data here. We have to delete these error data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transmission\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In transmission column I can see that, **nan**, **sedan** and **Sedan** are not data errors, hence we will delete them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see alot of redundent entries here, because data is case sentitive. Hence we can make all small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['make'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thoughts'></a>\n",
    "## üí≠ <span style=\"color: #20479b; font-weight: bold;\">My thoughts on the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my initial Data Exploration,\n",
    "- I can see that the dataset is huge with 558837 columns.\n",
    "- This dataset consits of alot of null values which can be deleted considering the size of the data.\n",
    "- VIN number is unique for each vahicle, hence it is not useful for me, hence I will drop the column.\n",
    "- I also noticed that the datatype of `saledate` column is object, and it also can time and timezone which we may not need.\n",
    "- `state` and `transmission` column has error data, which I can delete.\n",
    "\n",
    "\n",
    "\n",
    "I will be following the below steps to üßπ clean my data for further analysis.\n",
    "1. ‚ùé Drop all the rows containing `null` values.\n",
    "2. ‚ùé Drop columns `VIN`.\n",
    "3. ü™õ Convert the saledate column to Datetime format using `dateutil`.\n",
    "4. ü™õ Add columns `sale_year` and  `sale_month` using the `saledate` column.\n",
    "4. ü™õ Make column `make` all smalll.\n",
    "5. ü™õ Replace the make error in make with the standard make name.\n",
    "5. ‚ùé Drop the rows with error data from `state` and `transmission` columns.\n",
    "6. ‚úÖ Re-arrange the columns for better view. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning' ></a>\n",
    "## üßπ <span style=\"color: #20479b; font-weight: bold;\">Data Cleaning</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the null_percentage for each column is negligible. The max is for Transmission is 11.69%, which is negligible when we consider the datasize, i.e. 558837 of data. Hence I will be droping the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows.   :\", df.shape[0])\n",
    "print(\"=\"*30)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIN number is not usefull for my analysis, hence I will be droping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"vin\",axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can also see that sale date is different format. So I am going to use `dateutil.parser` module to clean it and convert it to datetime format. This module will automatically detect varies formats and convert it for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saledatetime']  =    pd.to_datetime(df['saledate' ].apply( parser.parse),utc=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can \n",
    "1. drop the older  `saledate` column, \n",
    "2. create a new `saledate` column which will have only the saledate and remove the time as it is not important for us.\n",
    "3. drop the `saledatetime`.\n",
    "4. add `sale_date` and `sale_year` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"saledate\",axis=1,inplace=True)\n",
    "df[\"saledate\"] = pd.to_datetime(df[\"saledatetime\"].dt.date)\n",
    "df.drop(\"saledatetime\",axis=1,inplace=True)\n",
    "df['sale_month'] = df['saledate'].dt.strftime('%B')\n",
    "df['sale_year'] = df['saledate'].dt.year\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will change the `make` column to all small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'] = df['make'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will replace the make names with standard one's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['make'].replace({'chev truck':'chevrolet','dodge tk':'dodge','ford tk':'ford','ford truck':'ford','gmc truck':'gmc','hyundai tk':'hyundai','land rover':'landrover',\n",
    "                    'mazda tk':'mazda','mercedes-b':'mercedes','mercedes-benz':'mercedes','vw':'volkswagen'},inplace=True)\n",
    "sorted(df['make'].astype(str).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df[ ~df[ 'state'].str.startswith('3vwd'  )]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to rearrange the columns in the dataframe for better visiblity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearranged_columns = ['year','make','model','trim','body','transmission','state','condition','color','interior','saledate','sale_year','sale_month','seller','sellingprice','mmr','odometer']\n",
    "df = df[rearranged_columns]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='questions'></a>  \n",
    "\n",
    "\n",
    "## ‚ùì <span style=\"color: #20479b; font-weight: bold;\">Business Questions</span>\n",
    "\n",
    "Questions\n",
    "1. What is sales propotion of car makers in each state?\n",
    "\n",
    "\n",
    "\n",
    "1. What is the trend in vehicle sales over the years based on the \"year\" column?\n",
    "2. Which vehicle make dominates the sales in the dataset?\n",
    "3. Are there any particular models that consistently perform better in terms of sales?\n",
    "4. How does the distribution of vehicle trims affect their selling prices?\n",
    "5. What body type is most commonly sold in the dataset?\n",
    "6. Is there any correlation between transmission type and selling price?\n",
    "7. Does the VIN (Vehicle Identification Number) have any influence on sales performance?\n",
    "8. Which states contribute the most to overall vehicle sales?\n",
    "9. How does the condition of the vehicle impact its selling price?\n",
    "10. Is there a relationship between odometer reading and selling price?\n",
    "11. Are certain colors more popular among buyers, and do they affect selling prices?\n",
    "12. Does the interior type influence the selling price of a vehicle?\n",
    "13. What type of sellers (e.g., dealerships, private sellers) are more successful in selling vehicles?\n",
    "14. Is there a correlation between the Manheim Market Report (MMR) value and the actual selling price of vehicles?\n",
    "15. How does the sale date (month, day of the week) affect the selling price and volume of vehicle sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">1Ô∏è‚É£ What is the sales propotion of car makers in New York(ny) and Texas(tx) for the last 3 years from the data?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will give them insigts of which car makers are in demand in New York and Texas. \n",
    "2. Further help them to plan out their purchase of second hand cars which are in demand.\n",
    "3. Help them deliver the their customers needs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my q1 i.e. `df_q1`.\n",
    "- Here I will filter the data for states NY and TX and where column year is past 3 year of it's max.\n",
    "- I will create another dataset `data` using `df_q1`, where I will group the data on `state` and `make` column and also get their count in `Sales in Units` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1 = df.loc[(df['state'].isin(['ny', 'tx'])) & (df['year'] >= (df['year'].max()-3))]\n",
    "data = df_q1.groupby ( ['state' , 'make']).size().reset_index( name ='Sales in Units' )\n",
    "data = data.sort_values(by='make').reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a bar graph for us\n",
    "- `fig` here is our Plotly figure object.\n",
    "- `px.bar()` is the function we will be using to plot the graph.\n",
    "- `data` is the dataset we will be using for the figure.\n",
    "- `x` - we need to specify the column we want to plot on x-axis, in this case it's `make`.\n",
    "- `y` - we need to specify the column we want to plot on y-axis, in this case it's `Sales in Units`.\n",
    "- `color` - is based on which the color coding will be done.\n",
    "- `h` - is how we want to plot the bars. In this case h stands for horizontal\n",
    "- `title` is the title of the figure.\n",
    "- `labe's` - are the labels we want for each figure, in my case I have made it all caps for make and State.\n",
    "- `legend_title_text` - is the title we want to set the title of the legend as.\n",
    "- `width` and `height`is the pixel size of the figure. In this case 1300*1200px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=px.bar(data, y='make', x='Sales in Units', color='state', orientation='h', title='Sales in Units by Make and State',\n",
    "           labels={'Sales in Units': 'Sales in Units', 'make': 'MAKE', 'state': 'STATE'},barmode='group')\n",
    "fig.update_layout(legend_title_text='State', width=1300, height=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the last 3 years of this datase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">2Ô∏è‚É£ What is the vehicle sales distribution by month for the last 5 years of the data?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will give them insigts of which which months of the year the vehicle purchase is more\n",
    "2. This will help them to plan out the car purchange during these months so that they can provide more options to the buyers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my question 2 i.e. `df_q2`. I will filter the data for column year is past 5 year of it's max.\n",
    "- Created a new column `sale_month_no` so that I can sort it based on month no.\n",
    "- Then I am grouping the data based on sale_month, and also getting a count for each month. \n",
    "- Sort the values based on `sale_month_no`.\n",
    "- I will create another dataset `data` using `df_q1`, where I will group the data on `state` and `make` column and also get their count in `Sales in Units` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q2 = df.loc[(df['year'] >= (df['year'].max()-5))].copy()\n",
    "df_q2['sale_month_no'] = df_q2['saledate'].dt.month\n",
    "data2 = df_q2.groupby ( ['sale_month','sale_month_no']).size().reset_index( name ='Sales in Units' )\n",
    "data2 = data2.sort_values(by='sale_month_no').reset_index(drop=True)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a bar graph for us\n",
    "- `fig` here is our Plotly figure object.\n",
    "- `px.bar()` is the function we will be using to plot the graph.\n",
    "- `data` is the dataset we will be using for the figure.\n",
    "- `x` - we need to specify the column we want to plot on x-axis, in this case it's `make`.\n",
    "- `y` - we need to specify the column we want to plot on y-axis, in this case it's `Sales in Units`.\n",
    "- `color` - is based on which the color coding will be done.\n",
    "- `h` - is how we want to plot the bars. In this case h stands for horizontal\n",
    "- `title` is the title of the figure.\n",
    "- `labe's` - are the labels we want for each figure, in my case I have made it all caps for make and State.\n",
    "- `legend_title_text` - is the title we want to set the title of the legend as.\n",
    "- `width` and `height`is the pixel size of the figure. In this case 1300*1200px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(data2, x = 'sale_month', y='Sales in Units', markers=True)\n",
    "fig.update_traces(line={'width': 4})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can in the diagram, the sales of the vehicles are high in the month of January, Febuary and June.\n",
    "- It is just below 80k units in the month of January.\n",
    "- The sales peaks in the month of Febuary by 80k units.\n",
    "- There is a decline in from march to April.\n",
    "- The sales rises in stedily in the month of May and June.\n",
    "- And then there is a decline again.\n",
    "\n",
    "- So, the company can hire more resources for sales so that they can make the maximun out of the customer buying behevious. And they need to be mindful in the month of April and July as the sales is 0 for these months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">3Ô∏è‚É£ Which make and model are better conditioned?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will show us whether make and model have anything to do with the condition of the vehicles.\n",
    "2. We will see which car and model has good condition.\n",
    "3. This will help the company in setting the price of the cars. If a cars condition is better for most of the users means that the car is welll built and hence can be sold for for a higher price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To maintain a standard we will consider the data in which saledate is older than 5 years.\n",
    "- I will first create a dataset for my question 2 i.e. `df_q2`. I will filter the data for column year is past 5 year of it's max.\n",
    "- Created a new column `sale_month_no` so that I can sort it based on month no.\n",
    "- Then I am grouping the data based on sale_month, and also getting a count for each month. \n",
    "- Sort the values based on `sale_month_no`.\n",
    "- I will create another dataset `data` using `df_q1`, where I will group the data on `state` and `make` column and also get their count in `Sales in Units` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q3 = df.loc[(df['year'] <= (df['year'].max()-5)) & (df['make'].isin(['ford','chevrolet','dodge']))].copy()\n",
    "data3 = df_q3.groupby ( ['make','state'])['condition'].mean().reset_index( name ='Avg Condition' )\n",
    "data3['Avg Condition'] = data3['Avg Condition'].round()\n",
    "data3 = data3.sort_values(by='make').reset_index(drop=True)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a bar graph for us\n",
    "- `fig` here is our Plotly figure object.\n",
    "- `px.bar()` is the function we will be using to plot the graph.\n",
    "- `data` is the dataset we will be using for the figure.\n",
    "- `x` - we need to specify the column we want to plot on x-axis, in this case it's `make`.\n",
    "- `y` - we need to specify the column we want to plot on y-axis, in this case it's `Sales in Units`.\n",
    "- `color` - is based on which the color coding will be done.\n",
    "- `h` - is how we want to plot the bars. In this case h stands for horizontal\n",
    "- `title` is the title of the figure.\n",
    "- `labe's` - are the labels we want for each figure, in my case I have made it all caps for make and State.\n",
    "- `legend_title_text` - is the title we want to set the title of the legend as.\n",
    "- `width` and `height`is the pixel size of the figure. In this case 1300*1200px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data = data3.pivot(index='state', columns='make', values='Avg Condition')\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(pivot_data, cmap='coolwarm', annot=True, fmt=\".2f\", linewidths=0.5, vmin= 0 , vmax=50)\n",
    "plt.title('Mean Condition by Make and Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Make')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Pivot the DataFrame to have 'state' as rows, 'make' as columns, and 'Avg Condition' as values\n",
    "pivot_data = data3.pivot(index='state', columns='make', values='Avg Condition')\n",
    "\n",
    "# Create a trace for the heatmap\n",
    "trace = go.Heatmap(z=pivot_data.values,\n",
    "                   x=pivot_data.columns,\n",
    "                   y=pivot_data.index,\n",
    "                   colorscale='RdBu',  # Choose a colorscale\n",
    "                   colorbar=dict(title='Avg Condition'),\n",
    "                   zmin=0, zmax=50,  # Set the color scale range\n",
    "                   hoverongaps=False,\n",
    "                   text=pivot_data.values,\n",
    "                   hoverinfo='text')\n",
    "\n",
    "# Create the layout\n",
    "layout = go.Layout(title='Mean Condition by Make and State',\n",
    "                   xaxis=dict(title='Make'),\n",
    "                   yaxis=dict(title='State'))\n",
    "\n",
    "# Create the figure and plot the heatmap\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=data3, x=\"make\", y='Avg Condition', hue=\"state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can in the diagram, the sales of the vehicles are high in the month of January, Febuary and June.\n",
    "- It is just below 80k units in the month of January.\n",
    "- The sales peaks in the month of Febuary by 80k units.\n",
    "- There is a decline in from march to April.\n",
    "- The sales rises in stedily in the month of May and June.\n",
    "- And then there is a decline again.\n",
    "\n",
    "- So, the company can hire more resources for sales so that they can make the maximun out of the customer buying behevious. And they need to be mindful in the month of April and July as the sales is 0 for these months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saledate'].dt.strftime('%B')\n",
    "df['saledate'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">4Ô∏è‚É£ What propotion of SUV sales have been taken up by each vehicle colors?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will show us the color preference of the customers in the market.\n",
    "2. This is will help the company is finding out what color is in demand.\n",
    "3. This is also help them in setting the re-sale price according to the demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my question 4 i.e. `df_q4`. I will filter the data for body.\n",
    "- Created a new column `propotion` which will have count of sales for each colors.\n",
    "- I will create another dataset `color_propotion` using `df_q4`, where I will devide the column `propotion` by total units to find a percentage.\n",
    "- And then we are going to present it in a form of pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q4 = df.loc[(df['body'].str.upper() == 'SUV'),['body','color']].copy()\n",
    "df_q4\n",
    "color_propotion = df_q4.groupby(['color']).size().reset_index()\n",
    "color_propotion\n",
    "color_propotion['propotion'] = color_propotion[0]\n",
    "color_propotion\n",
    "color_propotion.drop(0,axis=1,inplace=True)\n",
    "total_vehicle_sales = df_q4.groupby(['body','color']).size().sum()\n",
    "color_propotion['propotion'] = (color_propotion['propotion']/total_vehicle_sales)*100\n",
    "color_propotion.to_csv('/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/009. eda_on_ecommerce_dataset/dataset/output2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a pie chart to represent the color propotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = color_propotion['color']\n",
    "proportion = color_propotion['propotion']\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.pie(proportions, labels=colors, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Proportion of SUV Sales by Color') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üí¨&nbsp;&nbsp;Findings</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sale of color `black` is the most prominent, constituting of 21.8% of the sales.\n",
    "- Followed by `white` and `silver` which is 17.32% and 15.0% of the sales respectively.\n",
    "- With this pie chart we come to know the color preferences of the users.\n",
    "- This will help the company in developing product, sales and inventory management decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####     ‚ùì <span style=\"font-weight: bold;\">5Ô∏è‚É£ What is the co-relation between odometer reading and the percentage decrease from selling price to MMR of the car?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üíé&nbsp;&nbsp;Significance</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This will show us whether odometer reading have any connections for the MMR of the car.\n",
    "2. This will help the company to set pricing strategies accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  <span style=\"font-weight: bold;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;üìü&nbsp;&nbsp;Code</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will first create a dataset for my question 4 i.e. `df_q4`. I will filter the data for body.\n",
    "- I will sample only last 200 entries to simply it for us.\n",
    "- Created a new column `propotion` which will have count of sales for each colors.\n",
    "- I will create another dataset `color_propotion` using `df_q4`, where I will devide the column `propotion` by total units to find a percentage.\n",
    "- And then we are going to present it in a form of pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q5 = df[['odometer','sellingprice','mmr']].sample(n=200, random_state=42)\n",
    "df_q5['price_decrease_percentage'] = round(((df['sellingprice'] - df['mmr'])/df['sellingprice'])*100)\n",
    "df_q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here I will be using plotly to create a pie chart to represent the color propotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_q5['odometer']\n",
    "y = df_q5['price_decrease_percentage']\n",
    "\n",
    "z = np.polyfit(x,y,1)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ab = fig.add_subplot(1,1,1)\n",
    "ab.set_xlabel('odometer')\n",
    "ab.set_ylabel('price_decrease_percentage')\n",
    "\n",
    "ab.scatter(x, y, label='data')\n",
    "\n",
    "ab.plot(x, p(x),color='r',linestyle='dashed',label= 'fit' )\n",
    "ab.legend(loc='upper left')\n",
    "\n",
    "# # plt.scatter(x,y)\n",
    "# # plt.show()\n",
    "\n",
    "sns.scatterplot(data=df_q5, x=\"odometer\", y=\"price_decrease_percentage\", alpha=0.5, s=10)\n",
    "sns.plot(x,p(x),)\n",
    "plt.ylim(0, 40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear regression line\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "# Create scatter plot with seaborn\n",
    "sns.scatterplot(data=df_q5, x=\"odometer\", y=\"price_decrease_percentage\", alpha=0.5, s=10)\n",
    "\n",
    "# Plot the regression line\n",
    "sns.lineplot(x=x, y=p(x), color='r', linestyle='dashed', label='fit')\n",
    "\n",
    "# Set y-axis limits\n",
    "plt.ylim(0, 40)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "x = df_q5['odometer']\n",
    "y = df_q5['price_decrease_percentage']\n",
    "\n",
    "ax = sns.scatterplot(data=df_q5, x=\"odometer\", y=\"price_decrease_percentage\", alpha=0.5, s=10)\n",
    "ax.set_ylim(0, 50)  # Set y-axis limits\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
