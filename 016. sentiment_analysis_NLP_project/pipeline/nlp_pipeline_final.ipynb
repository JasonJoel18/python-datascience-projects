{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"display: flex; align-items: center; justify-content: center; font-weight: bold; font-size: 2em;\">\n",
    "  <img src=\"/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/016. sentiment_analysis_NLP_project/dataset/icons8-twitter-pastel/icons8-twitter-256.png\" alt=\"Your Image\" style=\"height: 2.5em; margin-right: 15px;\">\n",
    "  Twitter Post Classification\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üëãüèº **Introduction**\n",
    "\n",
    "<p style=\"text-align: justify;\">I am a data scientist. And my company wants me to build and NLP pipeline where it wants me to categorize my data as racist/sexist or not. The problem that currently the company is facing is there are alot of racist tweets on being posted online. And this causes a lot of distress among the other users, and there are potenial chances of them stop using the app due to these issues. Hence, we want to report these tweets and taken down as early as possible.</p>\n",
    "\n",
    "## üßø **Objective**\n",
    " <p style=\"text-align: justify;\">The objective of this project is that I will have to build a module which will try to classify the category of twitter reviews. For this my company has given me a dataset which is in csv format. It has three columns, id, tweet and the label. So I will be using these data in the csv file and building an NLP model ???????. Firstly I will be going through the full csv dataset and trying to remove the unwanted data if unsupported extensions. And then using these data I will be building a model. I will also be doing several experiments in order to improve the performance of the model. I will check if our dataset is balanced and if there is a requirement to increase the dataset so that our model can learn better from the data. Then I will choose the best-performing model to build my final model with the best-suited parameters.\n",
    " </p>\n",
    "\n",
    "**About the data**  \n",
    "This dataset contains 12 columns. This data set is from Kaggle. You can [**click here**](https://www.kaggle.com/datasets/mayurdalvi/twitter-sentiments-analysis-nlp) to view the dataset on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Content**\n",
    "\n",
    "##### ‚¨á [**Importing Libraries**](#library)\n",
    "##### üìä [**Importing Dataset**](#dataset)\n",
    "##### üó∫Ô∏è [**Exploring the dataset**](#exploration)\n",
    "##### üí≠ [**My taughts on the dataset**](#thoughts)\n",
    "##### ‚öôÔ∏è [**Pre-processing the data**](#processing)\n",
    "##### üîß [**Feature Engineering**](#feature)\n",
    "##### üóÇÔ∏è [**Selecting the best model for our dataset**](#selection)\n",
    "##### ‚úÖ [**Assessing which gives us the best results**](#assess)\n",
    "##### üéõÔ∏è [**Hyper-Parameter Tuning**](#tuning)\n",
    "##### üèÅ [**Final Model**](#Final)\n",
    "##### üí° [**Conclusion**](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Let's begin....***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='library'></a>\n",
    "## ‚¨á <span style=\"color: #20479b; font-weight: bold;\">Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start by importing the necessary libraries for my Exploratory Data Analysis tasks in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import  pandas as  pd\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.model_selection\n",
    "from  imblearn.over_sampling import SMOTE\n",
    "from  imblearn.over_sampling import ADASYN\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset'></a>  \n",
    "\n",
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">Importing Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst_dir = '/Users/jasonjoelpinto/Documents/GitHub/python-datascience-projects/016. sentiment_analysis_NLP_project/dataset/Twitter Sentiments.csv'\n",
    "dtst = pd.read_csv(dtst_dir)\n",
    "print(display(dtst.sample(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä <span style=\"color: #20479b; font-weight: bold;\">DELETEEE!!!!!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst = dtst.head(n=5000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exploration'></a>\n",
    "## üó∫Ô∏è <span style=\"color: #20479b; font-weight: bold;\">Exploring the dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can see that \n",
    "1. ID column is not necessary for us, hence we can delete it.\n",
    "2. tweets have alot of unnessary special characters, which we have to clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 31962 rows of data which is good so that the model can learn better from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here as we can see there are three columns i.e. id, label and tweet.\n",
    "As per the data authors, 1 here stands for rasist/sexist tweet and 0 stands for non racist comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = {}\n",
    "for column in dtst:\n",
    "    null_percentage[column] = round(( ( dtst[column].isnull().sum() ) / len(dtst)) * 100,2)\n",
    "np_dataset = pd.DataFrame( list( null_percentage.items() ),  columns=[  'column_name'  , 'null_percentage' ])\n",
    "np_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null entries in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no unnessary entries too. Which is a good thing for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ct = dtst['label'].value_counts()\n",
    "print('Each class count:')\n",
    "display(t_ct)\n",
    "print('1 class % is :',round(100*(t_ct[1]/(t_ct[0]+t_ct[1]))),'%')\n",
    "sns.barplot(x=t_ct.index, y=t_ct.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that our dataset is **heavily imbalanced**. We need to balance the dataset so that we can have good model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='thoughts'></a>\n",
    "## üí≠ <span style=\"color: #20479b; font-weight: bold;\">My thoughts on the dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per my initial Data Exploration,\n",
    "- I can see that the dataset big enough to build a good ML model.\n",
    "- I need to removed the ID column as we do not need it. \n",
    "- I will be also restructuring the column and moving the labels to the end to ease of reading.\n",
    "- The dataset consists of 31962 rows of data.\n",
    "- There are usertags and special characters in the column tweet. We need to remove those.\n",
    "- The dataset is heavily imbalanced. Hence we need to oversample the data.\n",
    "\n",
    "\n",
    "Evaluation Metrics:\n",
    "For this dataset I will be using, Accuracy, precision, F1 are the evaluation metrics.\n",
    "\n",
    "Considering all these above points, I will be following the below steps to \n",
    "\n",
    "**‚öôÔ∏è pre-process**\n",
    "1. üóëÔ∏è Delete the column ID.\n",
    "2. ü´∏üèª Move the column label to the end.\n",
    "3. üîÑ Convert the body to lower case\n",
    "4. üßπ Remove usertags.\n",
    "5. üßπ Remove special characters.\n",
    "<!-- 4. ‚ûó Spliting our main datset into two parts, one part for training and another for testing dataframe\n",
    "    - Doing it before testing or \n",
    "    - to avoid data Scalling and oversampling. -->\n",
    "\n",
    "**üîß feature Engineer**\n",
    "<!-- 1. ‚öñÔ∏è Scalling the numerical and categorical labels -->\n",
    "\n",
    "<!-- 2. üìà Oversampling the data for stroke = 1, Because of two main reasons.\n",
    "    - Our focus is on stroke detection and data for people who have stroke is very less.\n",
    "    - We do not have to worry about data size as well here, since it's not very huge. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='processing' ></a>\n",
    "## ‚öôÔ∏è <span style=\"color: #20479b; font-weight: bold;\">Pre-processing the data</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. üóëÔ∏è Delete the column ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst = dtst.drop(\n",
    "    'id', axis=1\n",
    ")\n",
    "dtst.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ü´∏üèª Move the column label to the end**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw_clm_odr = ['tweet','label']\n",
    "dtst = dtst[nw_clm_odr]\n",
    "dtst.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. üîÑ Convert the body to lower case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst['tweet_processed'] = dtst['tweet'].str.lower()\n",
    "dtst.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. #Ô∏è‚É£ Remove hashtags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst['tweet_processed'] = dtst[\n",
    "                             'tweet_processed'\n",
    "                             ].replace(\n",
    "                                        r'#([^\\s]+)', r'\\1', regex=True\n",
    "                                        )\n",
    "dtst.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.  üßπ Remove usertags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst['tweet_processed'] = dtst['tweet_processed'].replace(r'@[^\\s]+', '', regex=True)\n",
    "dtst.head(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.üóëÔ∏è Remove Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_punc(tweet):\n",
    "    tweet = tweet.translate(str.maketrans('','',string.punctuation))\n",
    "    return tweet\n",
    "\n",
    "dtst['tweet_processed'] = dtst['tweet_processed'].apply(rem_punc)\n",
    "dtst.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. üî¢ Clear all numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst['tweet_processed'] = dtst[\n",
    "                            'tweet_processed'\n",
    "                            ].replace(\n",
    "                                        r'\\d+', '', regex=True\n",
    "                                        )\n",
    "dtst.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. üßπ Remove special characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst['tweet_processed'] = dtst['tweet_processed'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "dtst.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Remove unwanted giberish characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_gib_space(twt):\n",
    "    twt = twt.encode('ascii', 'ignore').decode('ascii')\n",
    "    twt = re.sub(r'\\s+', ' ', twt).strip()\n",
    "    return twt\n",
    "\n",
    "dtst['tweet_processed'] = dtst['tweet_processed'].apply(rem_gib_space)\n",
    "dtst.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# porter = nltk.SnowballStemmer('english')\n",
    "\n",
    "# def preprocessor(input_text):\n",
    "#     tokenized_text = nltk.word_tokenize(input_text, language='english')\n",
    "#     stems = [porter.stem(t) for t in tokenized_text]\n",
    "#     return ' '.join(stems)\n",
    "\n",
    "# dtst['tweet_processed'] = dtst['tweet_processed'].apply(preprocessor)\n",
    "\n",
    "# dtst.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Creating a TD-IDF matrix for the tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtst['tweet_processed'] = dtst['tweet_processed'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trm_mdl = TfidfVectorizer(min_df=2)\n",
    "dtst = dtst.join(pd.DataFrame(trm_mdl.fit_transform(dtst['tweet_processed']).toarray()))\n",
    "inverted_index = {id: term for term, id in trm_mdl.vocabulary_.items()}\n",
    "dtst.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are unwanted characters in my tweets data. How can I remove those? Here is some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = '#model   i love u take with u all the time in ur√∞¬ü¬ì¬±!!! √∞¬ü¬ò¬ô√∞¬ü¬ò¬é√∞¬ü¬ë¬Ñ√∞¬ü¬ë¬Ö",
    "√∞¬ü¬í¬¶√∞¬ü¬í¬¶√∞¬ü¬í¬¶'\n",
    "# hi = text.encode('ascii', 'ignore').decode('ascii')\n",
    "# hi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. ‚ùé Splitting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = dtst['label'].values\n",
    "tr = tr.astype(float)\n",
    "\n",
    "ft = dtst.drop(columns=[\n",
    "                        'tweet',\n",
    "                        'tweet_processed',\n",
    "                        'label'\n",
    "                        ])\n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'No of features     : {ft.shape[1]}')\n",
    "print(f'Total rows of data : {ft.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_lst = []\n",
    "for itm in ft.columns:\n",
    "    if itm in inverted_index:\n",
    "        ft_lst.append(inverted_index[itm])\n",
    "    else:\n",
    "        ft_lst.append(itm)\n",
    "\n",
    "ft = ft.values\n",
    "ft = ft.astype('float')\n",
    "ft_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train_df,  ft_val_test_df,   tr_train_df,  tar_val_test_df = sklearn.model_selection.train_test_split(  ft , tr  ,  test_size = 0.35, shuffle=True, stratify=tr, random_state  =  40)\n",
    "ft_val_df,  ft_test_df,   tar_val_df,  tar_test_df = sklearn.model_selection.train_test_split(  ft_val_test_df , tar_val_test_df  ,  test_size = 0.50,shuffle=True, stratify=tr,random_state  =  40)\n",
    "\n",
    "print(f'Train features shape     : {ft_train_df.shape}')\n",
    "print(f'Train target shape       : {tr_train_df.shape}')\n",
    "print(39*'=')\n",
    "print(f'Validation features shape: {ft_val_df.shape}')\n",
    "print(f'Validation target shape  : {tar_val_df.shape}')\n",
    "print(39*'=')\n",
    "print(f'Test features shape      : {ft_test_df.shape}')\n",
    "print(f'Test target shape        : {tar_test_df.shape}')\n",
    "print(39*'=')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature' ></a>\n",
    "## üîß <span style=\"color: #20479b; font-weight: bold;\">Feature Engineering</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. üìà Oversampling the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **SMOTE** oversampling to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_smt =  SMOTE(  )\n",
    "ft_train_df_smt, tr_train_df_smt   =    mod_smt.fit_resample(\n",
    "                                                            ft_train_df, \n",
    "                                                            tr_train_df)\n",
    "\n",
    "print(\"fet_train_smot size :\",ft_train_df_smt.shape)\n",
    "print(\"tar_train_smot size :\",tr_train_df_smt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying **ADASYN** oversampling to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_adc =  ADASYN(  )\n",
    "ft_train_df_adc, tr_train_df_adc   =    mod_adc.fit_resample(\n",
    "                                                            ft_train_df, \n",
    "                                                            tr_train_df)\n",
    "\n",
    "print(\"fet_train_smot size :\",ft_train_df_adc.shape)\n",
    "print(\"tar_train_smot size :\",tr_train_df_adc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='selection'></a>\n",
    "## üóÇÔ∏è <span style=\"color: #20479b; font-weight: bold;\">Experimental Section</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have 10 different configurations and choose the best out of these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  table {\n",
    "    width: 100%;\n",
    "    border-collapse: collapse;\n",
    "    border: 1px solid #ddd;\n",
    "    font-family: Arial, sans-serif;\n",
    "  }\n",
    "  th, td {\n",
    "    padding: 12px;\n",
    "    text-align: left;\n",
    "    border-bottom: 1px solid #ddd;\n",
    "  }\n",
    "  th {\n",
    "    background-color: #03bafc;\n",
    "    color: #000;\n",
    "  }\n",
    "  tr:nth-child(even) {\n",
    "    background-color: #EEEEEE;\n",
    "  }\n",
    "  tr:hover {\n",
    "    background-color: #DBECFA; /* Light tint of blue for hover effect */\n",
    "  }\n",
    "  td:first-child {\n",
    "    font-weight: bold;\n",
    "  }\n",
    "   tr.mdl_config8 {\n",
    "    background-color: #95CD97; /* Dark light green */\n",
    "  } \n",
    "  .mdl_config8 {\n",
    "    background-color: #95CD97; /* Darker green for note */\n",
    "    padding: 8px;\n",
    "    font-style: italic;\n",
    "\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Model Config</th>\n",
    "      <th>Layers</th>\n",
    "      <th>Validation Accuracy</th>\n",
    "      <th>Observations</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><b>mdl_config1</b></td>\n",
    "      <td>Flatten(input_shape=(256,256,3))<br>Dense(4, activation='softmax')</td>\n",
    "      <td>0.8375</td>\n",
    "      <td>The accuracy was very low and it was fluctuating a lot. Hence, I will add one more dense hidden layer to the model.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config2</b></td>\n",
    "      <td>Flatten(input_shape=(256,256,3))<br>Dense(16, activation='relu')<br>Dense(4, activation='softmax')</td>\n",
    "      <td>0.4312</td>\n",
    "      <td>With the additional layer with 16 neurons, the accuracy dipped to 43%. I wanted to check if making the network more complex would help the model predict better.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config3</b></td>\n",
    "      <td>Flatten(input_shape=(256,256,3))<br>Dense(16, activation='relu')<br>tf.keras.layers.Dense(32, activation='relu')<br>Dense(4, activation='softmax')</td>\n",
    "      <td>0.63125</td>\n",
    "      <td>With the addition of another layer for 16 neurons, the accuracy increased by approximaterly 20%. Since these are images I wanted to check addition of convolutional and maxpooling layer will help, I will also increase the neurons for the dense layer</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config4</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>Dense(4, activation='softmax')</td>\n",
    "      <td>0.93125</td>\n",
    "      <td>Due to the convlutional layers it was able to read the images better. It was able to extract various features from the dataset. The accuracy has not increased to 93. Now I want to check it adding one more layer will help increase the accuracy.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config5</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>Dense(4, activation='softmax')</td>\n",
    "      <td>0.93750</td>\n",
    "      <td>There was no significant increace in the accuracy after adding another convolutional layer. But it was still slightly better than the previous configuration. Just to experiment I want to add another layer of convolution with more neurons and see if it increases the performance.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config6</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(64, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>Dense(4, activation='softmax')</td>\n",
    "      <td>0.99375</td>\n",
    "      <td>This was a huge improvement for me. The accuracy went to 99. The accuracy is fluctuating a little bit though. I do not want the model to overfit the train dataset hence I will experiment adding Early Stopping and see how it impacts</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config7</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(64, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>Dense(4, activation='softmax')<br>++EarlyStopping</td>\n",
    "      <td>0.996324</td>\n",
    "      <td>The accuracy has improved slightly and the accuracy curve is also much better. To avoid further overfit I will add Dropout layer see how it impacts</td>\n",
    "    <tr class=\"mdl_config8\">\n",
    "      <td><b>üëë mdl_config8</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(64, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>Dropout(0.5)<br>Dense(4, activation='softmax')<br>++EarlyStopping</td>\n",
    "      <td>0.98750</td>\n",
    "      <td class=\"observations\">The accuracy has decreased slightly, this may be because it was overfitting the data earlier. Let me add batch normalization and check if it will improve the accuracy.\n",
    "      <br><br><b>Note:</b> I have chosen this even if model 7 has better results because this model has both Early Stopping and Dropout, and even with that, it was able to score 0.98750 without overfitting the train data, which is great!!</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config9</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(64, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>BatchNormalization()<br>Dropout(0.5)<br>Dense(4, activation='softmax')<br>++EarlyStopping</td>\n",
    "      <td>0.98750</td>\n",
    "      <td>The accuracy is still the same. Now I want to check if changing the optimizers to sgd from adam will help increase the acccuracy</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config10</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(64, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>BatchNormalization()<br>Dropout(0.5)<br>Dense(4, activation='softmax')<br>++EarlyStopping</td>\n",
    "      <td>0.98750</td>\n",
    "      <td>With sgd the accuracy dropped to 72, and the accuracy fluctuates alot. So I will be going back to the adam optimizer. And I will try increasing the learning rate</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>mdl_config11</b></td>\n",
    "      <td>Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(32, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Conv2D(64, (2,2), 1, activation='relu', input_shape=(256,256,3))<br>MaxPooling2D()<br>Flatten()<br>Dense(256, activation='relu')<br>BatchNormalization()<br>Dropout(0.5)<br>Dense(4, activation='softmax')<br>++EarlyStopping</td>\n",
    "      <td>0.98750</td>\n",
    "      <td>With increase in learning rate thethe accuracy fluctuates even more.</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Final'></a>\n",
    "## üèÅ <span style=\"color: #20479b; font-weight: bold;\">Final Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_config8 = Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (2,2), 1, activation='relu', input_shape=(256,256,3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, (2,2), 1, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, (2,2), 1, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "mdl_config8.compile('adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='validation_loss',mode='max',patience=4, restore_best_weights=True)\n",
    "hist_config8 = mdl_config8.fit(train_btc_dt, epochs=20, validation_data=validation_btc_dt, callbacks=[early_stop])\n",
    "print('')\n",
    "print('=====================================================================================================')\n",
    "print('')\n",
    "\n",
    "mdl_config8.summary()\n",
    "\n",
    "fig, (acc, lss) = plt.subplots(1, 2, figsize=(7.5, 3))\n",
    "\n",
    "acc.plot(hist_config8.history['accuracy'], color='red', label='accuracy')\n",
    "acc.plot(hist_config8.history['val_accuracy'], color='blue', label='val_accuracy')\n",
    "acc.set_title('Accuracy', fontsize=20)\n",
    "acc.legend(loc=\"upper left\")\n",
    "\n",
    "lss.plot(hist_config8.history['loss'], color='red', label='train_loss')\n",
    "lss.plot(hist_config8.history['val_loss'], color='blue', label='validation_loss')\n",
    "lss.set_title('Loss', fontsize=20)\n",
    "lss.legend(loc=\"upper right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Evaluation'></a>\n",
    "## üí° <span style=\"color: #20479b; font-weight: bold;\"> Model Evaluation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "recl_lst = []\n",
    "prcn_lst = []\n",
    "acry_lst = []\n",
    "\n",
    "imgs = []\n",
    "tarpreds = []\n",
    "tars = []\n",
    "\n",
    "for btc in test_btc_dt.as_numpy_iterator():\n",
    "    img, tar = btc\n",
    "    tarpred = mdl_config8.predict(img)\n",
    "    tarpred = tarpred.argmax(axis=1)\n",
    "    recln = recall_score(tar, tarpred, average='macro')\n",
    "    prcnn = precision_score(tar, tarpred, average='macro')\n",
    "    acryn = accuracy_score(tar, tarpred)\n",
    "    prcn_lst.append(prcnn)\n",
    "    recl_lst.append(recln)\n",
    "    acry_lst.append(acryn)\n",
    "\n",
    "    # Append images, predictions, and ground truths for visualization\n",
    "    imgs.extend(img)\n",
    "    tarpreds.extend(tarpred)\n",
    "    tars.extend(tar)\n",
    "\n",
    "    # Break the loop if enough images are collected\n",
    "    if len(imgs) >= 6:\n",
    "        break\n",
    "\n",
    "print(f'Precision : {sum(prcn_lst)/len(prcn_lst)}')\n",
    "print(f'Recall    : {sum(recl_lst)/len(recl_lst)}')\n",
    "print(f'Accuracy  : {sum(acry_lst)/len(acry_lst)}')\n",
    "\n",
    "fig, am = plt.subplots(2, 3, figsize=(12, 8))\n",
    "am = am.ravel()\n",
    "\n",
    "for i,img in enumerate(imgs):\n",
    "    # Plot image\n",
    "    am[i].imshow(img)\n",
    "    am[i].set_xticks([])\n",
    "    am[i].set_yticks([])\n",
    "    \n",
    "    if tarpreds[i] == tar[i]:\n",
    "        ttl = 'green'\n",
    "    else:\n",
    "        ttl = 'red'\n",
    "    \n",
    "    am[i].set_title(f'Predicted: {eq_class[tarpreds[i]]}\\nActual: {eq_class[tars[i]]}', color=ttl)\n",
    "\n",
    "    if i >=5:\n",
    "        break\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the above plot, we were able to get very good scored and out of the 6 images we were able to predict most of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## üí° <span style=\"color: #20479b; font-weight: bold;\">Conclusion</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://icons8.com/icon/68193/twitter\">Twitter</a> icon by <a target=\"_blank\" href=\"https://icons8.com\">Icons8</a>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
